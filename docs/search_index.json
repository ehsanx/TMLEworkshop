[["index.html", "R Guide for TMLE in Medical Research Preface Background Goal Philosophy Pre-requisites Version history Contributor list License", " R Guide for TMLE in Medical Research Ehsan Karim &amp; Hanna Frank 2021-08-24 Preface Background In comparative effectiveness studies, researchers typically use propensity score methods. However, propensity score methods have known limitations in real-world scenarios, when the true data generating mechanism is unknown. Targeted maximum likelihood estimation (TMLE) is an alternative estimation method with a number of desirable statistical properties. It is a doubly robust method, making use of both the outcome model and propensity score model to generate an unbiased estimate as long as at least one of the models is correctly specified. TMLE also enables the integration of machine learning approaches. Despite the fact that this method has been shown to perform better than propensity score methods in a variety of scenarios, it is not widely used in medical research as the technical details of this approach are generally not well understood. Goal In this workshop we will present an introductory tutorial explaining an overview of TMLE and some of the relevant methods G-computation and IPW using one real epidemiological data, the steps to use the methods in R, and a demonstration of relevant R packages.  Philosophy Code-first philosophy is adopted for this workshop; demonstrating the analyses through one real data analysis problem used in the literature. This workshop is not theory-focused, nor utilizes simulated data to explain the ideas. Given the focus on implementation, theory is beyond the scope of this workshop. At the end of the workshop, we will provide key references where the theories are well explained. Pre-requisites Basic understanding of R language is required. A general understanding of multiple regression is expected. Familiarity with machine learning and epidemiological core concepts would be helpful, but not required. Deep understanding of causal inference or advanced statistical inference knowledge is not expected. Version history The workshop was first developed for R/Medicine Virtual Conference 2021, August 24th; title: `An Introductory R Guide for Targeted Maximum Likelihood Estimation in Medical Research. Contributor list Hanna Frank (SPPH, UBC) Ehsan Karim (SPPH, UBC) License The online version of this book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. You may share, adapt the content and may distribute your contributions under the same license (CC BY-NC-SA 4.0), but you have to give appropriate credit, and cannot use material for the commercial purposes. How to cite Karim, ME and Frank, H (2021) R Guide for TMLE in Medical Research, URL: ehsanx.github.io/TMLEworkshop/ "],["rhc-data-description.html", "Chapter 1 RHC data description 1.1 Data download 1.2 Analytic data 1.3 Notations 1.4 Variables 1.5 Table 1 stratified by RHC exposure 1.6 Basic regression analysis 1.7 Comparison with literature", " Chapter 1 RHC data description There is a widespread belief among cardiologists that the right heart catheterization (RHC hereafter; a monitoring device for measurement of cardiac function) is helpful in managing critically ill patients in the intensive care unit. Connors et al. (1996) examined the association of RHC use during the first 24 hours of care in the intensive care unit and a number of health-outcomes such as length of stay (hospital). 1.1 Data download Data is freely available from Vanderbilt Biostatistics. # load the dataset ObsData &lt;- read.csv(&quot;https://hbiostat.org/data/repo/rhc.csv&quot;, header = TRUE) saveRDS(ObsData, file = &quot;data/rhc.RDS&quot;) 1.2 Analytic data Below we show the process of creating the analytic data (optional). # add column for outcome Y: length of stay # Y = date of discharge - study admission date # Y = date of death - study admission date if date of discharge not available ObsData$Y &lt;- ObsData$dschdte - ObsData$sadmdte ObsData$Y[is.na(ObsData$Y)] &lt;- ObsData$dthdte[is.na(ObsData$Y)] - ObsData$sadmdte[is.na(ObsData$Y)] # remove outcomes we are not examining in this example ObsData &lt;- dplyr::select(ObsData, !c(dthdte, lstctdte, dschdte, death, t3d30, dth30, surv2md1)) # remove unnecessary and problematic variables ObsData &lt;- dplyr::select(ObsData, !c(sadmdte, ptid, X, adld3p, urin1, cat2)) # convert all categorical variables to factors factors &lt;- c(&quot;cat1&quot;, &quot;ca&quot;, &quot;cardiohx&quot;, &quot;chfhx&quot;, &quot;dementhx&quot;, &quot;psychhx&quot;, &quot;chrpulhx&quot;, &quot;renalhx&quot;, &quot;liverhx&quot;, &quot;gibledhx&quot;, &quot;malighx&quot;, &quot;immunhx&quot;, &quot;transhx&quot;, &quot;amihx&quot;, &quot;sex&quot;, &quot;dnr1&quot;, &quot;ninsclas&quot;, &quot;resp&quot;, &quot;card&quot;, &quot;neuro&quot;, &quot;gastr&quot;, &quot;renal&quot;, &quot;meta&quot;, &quot;hema&quot;, &quot;seps&quot;, &quot;trauma&quot;, &quot;ortho&quot;, &quot;race&quot;, &quot;income&quot;) ObsData[factors] &lt;- lapply(ObsData[factors], as.factor) # convert our treatment A (RHC vs. No RHC) to a binary variable ObsData$A &lt;- ifelse(ObsData$swang1 == &quot;RHC&quot;, 1, 0) ObsData &lt;- dplyr::select(ObsData, !swang1) # Categorize the variables to match with the original paper ObsData$age &lt;- cut(ObsData$age,breaks=c(-Inf, 50, 60, 70, 80, Inf),right=FALSE) ObsData$race &lt;- factor(ObsData$race, levels=c(&quot;white&quot;,&quot;black&quot;,&quot;other&quot;)) ObsData$sex &lt;- as.factor(ObsData$sex) ObsData$sex &lt;- relevel(ObsData$sex, ref = &quot;Male&quot;) ObsData$cat1 &lt;- as.factor(ObsData$cat1) levels(ObsData$cat1) &lt;- c(&quot;ARF&quot;,&quot;CHF&quot;,&quot;Other&quot;,&quot;Other&quot;,&quot;Other&quot;, &quot;Other&quot;,&quot;Other&quot;,&quot;MOSF&quot;,&quot;MOSF&quot;) ObsData$ca &lt;- as.factor(ObsData$ca) levels(ObsData$ca) &lt;- c(&quot;Metastatic&quot;,&quot;None&quot;,&quot;Localized (Yes)&quot;) ObsData$ca &lt;- factor(ObsData$ca, levels=c(&quot;None&quot;, &quot;Localized (Yes)&quot;,&quot;Metastatic&quot;)) # Rename variables names(ObsData) &lt;- c(&quot;Disease.category&quot;, &quot;Cancer&quot;, &quot;Cardiovascular&quot;, &quot;Congestive.HF&quot;, &quot;Dementia&quot;, &quot;Psychiatric&quot;, &quot;Pulmonary&quot;, &quot;Renal&quot;, &quot;Hepatic&quot;, &quot;GI.Bleed&quot;, &quot;Tumor&quot;, &quot;Immunosupperssion&quot;, &quot;Transfer.hx&quot;, &quot;MI&quot;, &quot;age&quot;, &quot;sex&quot;, &quot;edu&quot;, &quot;DASIndex&quot;, &quot;APACHE.score&quot;, &quot;Glasgow.Coma.Score&quot;, &quot;blood.pressure&quot;, &quot;WBC&quot;, &quot;Heart.rate&quot;, &quot;Respiratory.rate&quot;, &quot;Temperature&quot;, &quot;PaO2vs.FIO2&quot;, &quot;Albumin&quot;, &quot;Hematocrit&quot;, &quot;Bilirubin&quot;, &quot;Creatinine&quot;, &quot;Sodium&quot;, &quot;Potassium&quot;, &quot;PaCo2&quot;, &quot;PH&quot;, &quot;Weight&quot;, &quot;DNR.status&quot;, &quot;Medical.insurance&quot;, &quot;Respiratory.Diag&quot;, &quot;Cardiovascular.Diag&quot;, &quot;Neurological.Diag&quot;, &quot;Gastrointestinal.Diag&quot;, &quot;Renal.Diag&quot;, &quot;Metabolic.Diag&quot;, &quot;Hematologic.Diag&quot;, &quot;Sepsis.Diag&quot;, &quot;Trauma.Diag&quot;, &quot;Orthopedic.Diag&quot;, &quot;race&quot;, &quot;income&quot;, &quot;Y&quot;, &quot;A&quot;) saveRDS(ObsData, file = &quot;data/rhcAnalytic.RDS&quot;) 1.3 Notations Notations Example in RHC study \\(A\\): Exposure status RHC \\(Y\\): Observed outcome length of stay \\(L\\): Covariates See below 1.4 Variables baselinevars &lt;- names(dplyr::select(ObsData, !c(A,Y))) baselinevars ## [1] &quot;Disease.category&quot; &quot;Cancer&quot; &quot;Cardiovascular&quot; ## [4] &quot;Congestive.HF&quot; &quot;Dementia&quot; &quot;Psychiatric&quot; ## [7] &quot;Pulmonary&quot; &quot;Renal&quot; &quot;Hepatic&quot; ## [10] &quot;GI.Bleed&quot; &quot;Tumor&quot; &quot;Immunosupperssion&quot; ## [13] &quot;Transfer.hx&quot; &quot;MI&quot; &quot;age&quot; ## [16] &quot;sex&quot; &quot;edu&quot; &quot;DASIndex&quot; ## [19] &quot;APACHE.score&quot; &quot;Glasgow.Coma.Score&quot; &quot;blood.pressure&quot; ## [22] &quot;WBC&quot; &quot;Heart.rate&quot; &quot;Respiratory.rate&quot; ## [25] &quot;Temperature&quot; &quot;PaO2vs.FIO2&quot; &quot;Albumin&quot; ## [28] &quot;Hematocrit&quot; &quot;Bilirubin&quot; &quot;Creatinine&quot; ## [31] &quot;Sodium&quot; &quot;Potassium&quot; &quot;PaCo2&quot; ## [34] &quot;PH&quot; &quot;Weight&quot; &quot;DNR.status&quot; ## [37] &quot;Medical.insurance&quot; &quot;Respiratory.Diag&quot; &quot;Cardiovascular.Diag&quot; ## [40] &quot;Neurological.Diag&quot; &quot;Gastrointestinal.Diag&quot; &quot;Renal.Diag&quot; ## [43] &quot;Metabolic.Diag&quot; &quot;Hematologic.Diag&quot; &quot;Sepsis.Diag&quot; ## [46] &quot;Trauma.Diag&quot; &quot;Orthopedic.Diag&quot; &quot;race&quot; ## [49] &quot;income&quot; 1.5 Table 1 stratified by RHC exposure Only for some demographic and co-morbidity variables; match with Table 1 in Connors et al. (1996). require(tableone) tab0 &lt;- CreateTableOne(vars = c(&quot;age&quot;, &quot;sex&quot;, &quot;race&quot;, &quot;Disease.category&quot;, &quot;Cancer&quot;), data = ObsData, strata = &quot;A&quot;, test = FALSE) print(tab0, showAllLevels = FALSE, ) ## Stratified by A ## 0 1 ## n 3551 2184 ## age (%) ## [-Inf,50) 884 (24.9) 540 (24.7) ## [50,60) 546 (15.4) 371 (17.0) ## [60,70) 812 (22.9) 577 (26.4) ## [70,80) 809 (22.8) 529 (24.2) ## [80, Inf) 500 (14.1) 167 ( 7.6) ## sex = Female (%) 1637 (46.1) 906 (41.5) ## race (%) ## white 2753 (77.5) 1707 (78.2) ## black 585 (16.5) 335 (15.3) ## other 213 ( 6.0) 142 ( 6.5) ## Disease.category (%) ## ARF 1581 (44.5) 909 (41.6) ## CHF 247 ( 7.0) 209 ( 9.6) ## Other 955 (26.9) 208 ( 9.5) ## MOSF 768 (21.6) 858 (39.3) ## Cancer (%) ## None 2652 (74.7) 1727 (79.1) ## Localized (Yes) 638 (18.0) 334 (15.3) ## Metastatic 261 ( 7.4) 123 ( 5.6) Only outcome variable (Length of stay); slightly different than Table 2 in Connors et al. (1996) (means 20.5 vs. 25.7; and medians 13 vs. 17). tab1 &lt;- CreateTableOne(vars = c(&quot;Y&quot;), data = ObsData, strata = &quot;A&quot;, test = FALSE) print(tab1, showAllLevels = FALSE, ) ## Stratified by A ## 0 1 ## n 3551 2184 ## Y (mean (SD)) 19.53 (23.59) 24.86 (28.90) median(ObsData$Y[ObsData$A==0]); median(ObsData$Y[ObsData$A==1]) ## [1] 12 ## [1] 16 1.6 Basic regression analysis 1.6.1 Crude analysis # adjust the exposure variable (primary interest) fit0 &lt;- lm(Y~A, data = ObsData) require(Publish) crude.fit &lt;- publish(fit0, digits=1)$regressionTable[2,] crude.fit ## Variable Units Coefficient CI.95 p-value ## 2 A 5.3 [4.0;6.7] &lt;0.1 1.6.2 Adjusted analysis # adjust the exposure variable (primary interest) + covariates out.formula &lt;- as.formula(paste(&quot;Y~ A +&quot;, paste(baselinevars, collapse = &quot;+&quot;))) fit1 &lt;- lm(out.formula, data = ObsData) adj.fit &lt;- publish(fit1, digits=1)$regressionTable[2,] saveRDS(fit1, file = &quot;data/adjreg.RDS&quot;) out.formula ## Y ~ A + Disease.category + Cancer + Cardiovascular + Congestive.HF + ## Dementia + Psychiatric + Pulmonary + Renal + Hepatic + GI.Bleed + ## Tumor + Immunosupperssion + Transfer.hx + MI + age + sex + ## edu + DASIndex + APACHE.score + Glasgow.Coma.Score + blood.pressure + ## WBC + Heart.rate + Respiratory.rate + Temperature + PaO2vs.FIO2 + ## Albumin + Hematocrit + Bilirubin + Creatinine + Sodium + ## Potassium + PaCo2 + PH + Weight + DNR.status + Medical.insurance + ## Respiratory.Diag + Cardiovascular.Diag + Neurological.Diag + ## Gastrointestinal.Diag + Renal.Diag + Metabolic.Diag + Hematologic.Diag + ## Sepsis.Diag + Trauma.Diag + Orthopedic.Diag + race + income adj.fit Table 1.1: VariableUnitsCoefficientCI.95p-value A2.9[1.4;4.4]&lt;0.1 1.6.3 Regression diagnostics plot(fit1) Diagnostics do not necessarily look so good. 1.7 Comparison with literature Connors et al. (1996) conducted a propensity score matching analysis. Table 5 in Connors et al. (1996) showed that, after propensity score pair (1-to-1) matching, means of length of stay (\\(Y\\)), when stratified by RHC (\\(A\\)) were not significantly different (\\(p = 0.14\\)). 1.7.1 PSM in RHC data We also conduct propensity score pair matching analysis, as follows. Note: In this workshop, we will not cover Propensity Score Matching (PSM) in this workshop. If you want to learn more about this, feel free to check out this other workshop: Understanding Propensity Score Matching. set.seed(111) require(MatchIt) ps.formula &lt;- as.formula(paste(&quot;A~&quot;, paste(baselinevars, collapse = &quot;+&quot;))) PS.fit &lt;- glm(ps.formula,family=&quot;binomial&quot;, data=ObsData) ObsData$PS &lt;- predict(PS.fit, newdata = ObsData, type=&quot;response&quot;) logitPS &lt;- -log(1/ObsData$PS - 1) match.obj &lt;- matchit(ps.formula, data =ObsData, distance = ObsData$PS, method = &quot;nearest&quot;, replace=FALSE, ratio = 1, caliper = .2*sd(logitPS)) 1.7.1.1 PSM diagnostics require(cobalt) bal.plot(match.obj, var.name = &quot;distance&quot;, which = &quot;both&quot;, type = &quot;histogram&quot;, mirror = TRUE) bal.tab(match.obj, un = TRUE, thresholds = c(m = .1)) ## Call ## matchit(formula = ps.formula, data = ObsData, method = &quot;nearest&quot;, ## distance = ObsData$PS, replace = FALSE, caliper = 0.2 * sd(logitPS), ## ratio = 1) ## ## Balance Measures ## Type Diff.Un Diff.Adj M.Threshold ## distance Distance 1.1558 0.1820 ## Disease.category_ARF Binary -0.0290 -0.0178 Balanced, &lt;0.1 ## Disease.category_CHF Binary 0.0261 -0.0006 Balanced, &lt;0.1 ## Disease.category_Other Binary -0.1737 -0.0092 Balanced, &lt;0.1 ## Disease.category_MOSF Binary 0.1766 0.0276 Balanced, &lt;0.1 ## Cancer_None Binary 0.0439 0.0075 Balanced, &lt;0.1 ## Cancer_Localized (Yes) Binary -0.0267 -0.0109 Balanced, &lt;0.1 ## Cancer_Metastatic Binary -0.0172 0.0035 Balanced, &lt;0.1 ## Cardiovascular Binary 0.0445 -0.0104 Balanced, &lt;0.1 ## Congestive.HF Binary 0.0268 0.0012 Balanced, &lt;0.1 ## Dementia Binary -0.0472 -0.0023 Balanced, &lt;0.1 ## Psychiatric Binary -0.0348 -0.0081 Balanced, &lt;0.1 ## Pulmonary Binary -0.0737 -0.0138 Balanced, &lt;0.1 ## Renal Binary 0.0066 -0.0058 Balanced, &lt;0.1 ## Hepatic Binary -0.0124 -0.0023 Balanced, &lt;0.1 ## GI.Bleed Binary -0.0122 -0.0006 Balanced, &lt;0.1 ## Tumor Binary -0.0423 -0.0052 Balanced, &lt;0.1 ## Immunosupperssion Binary 0.0358 -0.0046 Balanced, &lt;0.1 ## Transfer.hx Binary 0.0554 0.0115 Balanced, &lt;0.1 ## MI Binary 0.0139 -0.0012 Balanced, &lt;0.1 ## age_[-Inf,50) Binary -0.0017 0.0063 Balanced, &lt;0.1 ## age_[50,60) Binary 0.0161 0.0104 Balanced, &lt;0.1 ## age_[60,70) Binary 0.0355 0.0006 Balanced, &lt;0.1 ## age_[70,80) Binary 0.0144 -0.0132 Balanced, &lt;0.1 ## age_[80, Inf) Binary -0.0643 -0.0040 Balanced, &lt;0.1 ## sex_Female Binary -0.0462 -0.0092 Balanced, &lt;0.1 ## edu Contin. 0.0910 0.0293 Balanced, &lt;0.1 ## DASIndex Contin. 0.0654 0.0263 Balanced, &lt;0.1 ## APACHE.score Contin. 0.4837 0.0813 Balanced, &lt;0.1 ## Glasgow.Coma.Score Contin. -0.1160 -0.0147 Balanced, &lt;0.1 ## blood.pressure Contin. -0.4869 -0.0680 Balanced, &lt;0.1 ## WBC Contin. 0.0799 -0.0096 Balanced, &lt;0.1 ## Heart.rate Contin. 0.1460 -0.0005 Balanced, &lt;0.1 ## Respiratory.rate Contin. -0.1641 -0.0361 Balanced, &lt;0.1 ## Temperature Contin. -0.0209 -0.0219 Balanced, &lt;0.1 ## PaO2vs.FIO2 Contin. -0.4566 -0.0560 Balanced, &lt;0.1 ## Albumin Contin. -0.2010 -0.0281 Balanced, &lt;0.1 ## Hematocrit Contin. -0.2954 -0.0293 Balanced, &lt;0.1 ## Bilirubin Contin. 0.1329 0.0319 Balanced, &lt;0.1 ## Creatinine Contin. 0.2678 0.0339 Balanced, &lt;0.1 ## Sodium Contin. -0.0927 -0.0218 Balanced, &lt;0.1 ## Potassium Contin. -0.0274 0.0064 Balanced, &lt;0.1 ## PaCo2 Contin. -0.2880 -0.0456 Balanced, &lt;0.1 ## PH Contin. -0.1163 -0.0228 Balanced, &lt;0.1 ## Weight Contin. 0.2640 0.0241 Balanced, &lt;0.1 ## DNR.status_Yes Binary -0.0696 0.0006 Balanced, &lt;0.1 ## Medical.insurance_Medicaid Binary -0.0395 -0.0035 Balanced, &lt;0.1 ## Medical.insurance_Medicare Binary -0.0327 -0.0075 Balanced, &lt;0.1 ## Medical.insurance_Medicare &amp; Medicaid Binary -0.0144 -0.0058 Balanced, &lt;0.1 ## Medical.insurance_No insurance Binary 0.0099 0.0046 Balanced, &lt;0.1 ## Medical.insurance_Private Binary 0.0624 0.0259 Balanced, &lt;0.1 ## Medical.insurance_Private &amp; Medicare Binary 0.0143 -0.0138 Balanced, &lt;0.1 ## Respiratory.Diag_Yes Binary -0.1277 -0.0299 Balanced, &lt;0.1 ## Cardiovascular.Diag_Yes Binary 0.1395 0.0236 Balanced, &lt;0.1 ## Neurological.Diag_Yes Binary -0.1079 -0.0098 Balanced, &lt;0.1 ## Gastrointestinal.Diag_Yes Binary 0.0453 0.0052 Balanced, &lt;0.1 ## Renal.Diag_Yes Binary 0.0264 0.0040 Balanced, &lt;0.1 ## Metabolic.Diag_Yes Binary -0.0059 0.0017 Balanced, &lt;0.1 ## Hematologic.Diag_Yes Binary -0.0146 -0.0035 Balanced, &lt;0.1 ## Sepsis.Diag_Yes Binary 0.0912 0.0138 Balanced, &lt;0.1 ## Trauma.Diag_Yes Binary 0.0105 0.0017 Balanced, &lt;0.1 ## Orthopedic.Diag_Yes Binary 0.0010 0.0012 Balanced, &lt;0.1 ## race_white Binary 0.0063 0.0069 Balanced, &lt;0.1 ## race_black Binary -0.0114 -0.0081 Balanced, &lt;0.1 ## race_other Binary 0.0050 0.0012 Balanced, &lt;0.1 ## income_$11-$25k Binary 0.0062 -0.0104 Balanced, &lt;0.1 ## income_$25-$50k Binary 0.0391 0.0173 Balanced, &lt;0.1 ## income_&gt; $50k Binary 0.0165 0.0086 Balanced, &lt;0.1 ## income_Under $11k Binary -0.0618 -0.0155 Balanced, &lt;0.1 ## ## Balance tally for mean differences ## count ## Balanced, &lt;0.1 68 ## Not Balanced, &gt;0.1 0 ## ## Variable with the greatest mean difference ## Variable Diff.Adj M.Threshold ## APACHE.score 0.0813 Balanced, &lt;0.1 ## ## Sample sizes ## Control Treated ## All 3551 2184 ## Matched 1739 1739 ## Unmatched 1812 445 love.plot(match.obj, binary = &quot;std&quot;, thresholds = c(m = .1)) The love plot suggests satisfactory propensity score matching (all SMD &lt; 0.1). 1.7.1.2 PSM results matched.data &lt;- match.data(match.obj) tab1y &lt;- CreateTableOne(vars = c(&quot;Y&quot;), data = matched.data, strata = &quot;A&quot;, test = TRUE) print(tab1y, showAllLevels = FALSE, test = TRUE) ## Stratified by A ## 0 1 p test ## n 1739 1739 ## Y (mean (SD)) 21.22 (25.36) 24.47 (28.79) &lt;0.001 Hence, our conclusion based on propensity score pair matched data (\\(p \\lt 0.001\\)) is different than Table 5 in Connors et al. (1996) (\\(p = 0.14\\)). Variability in results for 1-to-1 matching is possible, and modelling choices may be different (we used caliper option here). We can also estimate the effect of RHC on length of stay using propensity score-matched sample: fit.matched &lt;- glm(Y~A, family=gaussian, data = matched.data) publish(fit.matched) ## Variable Units Coefficient CI.95 p-value ## (Intercept) 21.22 [19.94;22.49] &lt; 1e-04 ## A 3.25 [1.45;5.05] 0.0004145 saveRDS(fit.matched, file = &quot;data/match.RDS&quot;) 1.7.2 TMLE in RHC data There are other papers that have used RHC data (Keele and Small 2021, 2018). Keele and Small (2021) used TMLE (with super learner) method in estimating the impact of RHC on length of stay, and found point estimate \\(2.01 (95\\% CI: 0.6-3.41)\\). In todays workshop, we will learn about TMLE-SL methods. References "],["g-computation.html", "Chapter 2 G-computation 2.1 Closer look at the data 2.2 Use Regression for predicting outcome 2.3 Parametric G-computation 2.4 Estimating the confidence intervals", " Chapter 2 G-computation 2.1 Closer look at the data # Read the data saved at the last chapter ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) dim(ObsData) ## [1] 5735 51 In this dataset, we have 5,735 subjects, 1 outcome variable (\\(Y\\) = length of stay), 1 exposure variable (\\(A\\) = RHC status), and 49 covariates. 2.1.1 View data from 6 participants Lets focus on only first 6 columns, with only 3 variables. small.data &lt;- ObsData[1:6,c(&quot;sex&quot;,&quot;A&quot;,&quot;Y&quot;)] kable(small.data) sex A Y Male 0 9 Female 1 45 Female 1 60 Female 0 37 Male 1 2 Female 0 7 2.1.2 New notations Notations Example in RHC study \\(A\\): Exposure status RHC \\(Y\\): Observed outcome length of stay \\(Y(A=1)\\) = potential outcome when exposed length of stay when RHC used \\(Y(A=0)\\) = potential outcome when not exposed length of stay when RHC not used \\(L\\): covariates \\(49\\) covariates For explaining the concepts in this chapter, we will convert our data representation from Covariate Exposure Observed outcome \\(L\\) \\(A\\) \\(Y\\) sex RHC length of stay to the following representation: Covariate Exposure Outcome under exposed Outcome under unexposed \\(L\\) \\(A\\) \\(Y(A=1)\\) \\(Y(A=0)\\) sex RHC length of stay under RHC length of stay under no RHC 2.1.3 Restructure the data to estimate treatment effect In causal inference literature, often the data is structured in such a way that the outcomes \\(Y\\) under different treatments \\(A\\) are in different columns. What we are doing here is we are distinguishing \\(Y(A=1)\\) from \\(Y(A=0)\\). small.data$id &lt;- c(&quot;John&quot;,&quot;Emma&quot;,&quot;Isabella&quot;,&quot;Sophia&quot;,&quot;Luke&quot;, &quot;Mia&quot;) small.data$Y1 &lt;- ifelse(small.data$A==1, small.data$Y, NA) small.data$Y0 &lt;- ifelse(small.data$A==0, small.data$Y, NA) small.data$TE &lt;- small.data$Y1 - small.data$Y0 small.data &lt;- small.data[c(&quot;id&quot;, &quot;sex&quot;,&quot;A&quot;,&quot;Y1&quot;,&quot;Y0&quot;, &quot;TE&quot;)] small.data$Y &lt;- NULL small.data$sex &lt;- as.character(small.data$sex) m.Y1 &lt;- mean(small.data$Y1, na.rm = TRUE) m.Y0 &lt;- mean(small.data$Y0, na.rm = TRUE) mean.values &lt;- round(c(NA,NA, NA, m.Y1, m.Y0, m.Y1 - m.Y0),0) small.data2 &lt;- rbind(small.data, mean.values) kable(small.data2, booktabs = TRUE, digits=1, col.names = c(&quot;Subject ID&quot;,&quot;Sex&quot;, &quot;RHC status (A)&quot;, &quot;Y when A=1 (RHC)&quot;, &quot;Y when A=0 (no RHC)&quot;, &quot;Treatment Effect&quot;))%&gt;% row_spec(7, bold = TRUE, color = &quot;white&quot;, background = &quot;#D7261E&quot;) Subject ID Sex RHC status (A) Y when A=1 (RHC) Y when A=0 (no RHC) Treatment Effect John Male 0 9 Emma Female 1 45 Isabella Female 1 60 Sophia Female 0 37 Luke Male 1 2 Mia Female 0 7 36 18 18 Then it is easy to see the mean outcome under treated group (RHC) the mean outcome under untreated group (no RHC) and the difference between these two means is the treatment effect. 2.1.4 Treat the problem as a missing value problem Restructure the problem as a missing data problem. Instead of just estimating treatment effect on an average level, an alternate could be to impute mean outcomes for the treated subjects impute mean outcomes for the untreated subjects Calculate individual treatment effect estimate then calculate the average treatment effect small.data0 &lt;- small.data small.data$Y1[is.na(small.data$Y1)] &lt;- round(m.Y1) small.data$Y0[is.na(small.data$Y0)] &lt;- round(m.Y0) small.data$TE &lt;- small.data$Y1 - small.data$Y0 m.Y1 &lt;- mean(small.data$Y1) m.Y1 ## [1] 35.83333 m.Y0 &lt;- mean(small.data$Y0) m.Y0 ## [1] 17.83333 m.TE &lt;- mean(small.data$TE) mean.values &lt;- round(c(NA,NA, NA, m.Y1, m.Y0, m.TE),0) small.data2 &lt;- rbind(small.data, mean.values) small.data2$Y1[1:6] &lt;- cell_spec(small.data2$Y1[1:6], color = ifelse(small.data2$Y1[1:6] == round(m.Y1), &quot;red&quot;, &quot;black&quot;), background = ifelse(small.data2$Y1[1:6] == round(m.Y1), &quot;yellow&quot;, &quot;white&quot;), bold = ifelse(small.data2$Y1[1:6] == round(m.Y1), TRUE, FALSE)) small.data2$Y0[1:6] &lt;- cell_spec(small.data2$Y0[1:6], color = ifelse(small.data2$Y0[1:6] == round(m.Y0), &quot;red&quot;, &quot;black&quot;), background = ifelse(small.data2$Y0[1:6] == round(m.Y0), &quot;yellow&quot;, &quot;white&quot;), bold = ifelse(small.data2$Y0[1:6] == round(m.Y0), TRUE, FALSE)) kable(small.data2, booktabs = TRUE, digits=1, escape = FALSE, col.names = c(&quot;Subject ID&quot;,&quot;Sex&quot;, &quot;RHC status (A)&quot;, &quot;Y when A=1 (RHC)&quot;, &quot;Y when A=0 (no RHC)&quot;, &quot;Treatment Effect&quot;))%&gt;% row_spec(7, bold = TRUE, color = &quot;white&quot;, background = &quot;#D7261E&quot;) Subject ID Sex RHC status (A) Y when A=1 (RHC) Y when A=0 (no RHC) Treatment Effect John Male 0 36 9 27 Emma Female 1 45 18 27 Isabella Female 1 60 18 42 Sophia Female 0 36 37 -1 Luke Male 1 2 18 -16 Mia Female 0 36 7 29 36 18 18 2.1.5 Impute better value? Assume that sex variable is acting as a confounder. Then, it might make more sense to restrict imputing outcome values specific to male and female participants. impute means specific to males for male subjects, and separately impute means specific to females for female subjects. small.data &lt;- small.data0 m.Y1m &lt;- mean(small.data$Y1[small.data$sex == &quot;Male&quot;], na.rm = TRUE) m.Y1m ## [1] 2 m.Y1f &lt;- mean(small.data$Y1[small.data$sex == &quot;Female&quot;], na.rm = TRUE) m.Y1f ## [1] 52.5 m.Y0m &lt;- mean(small.data$Y0[small.data$sex == &quot;Male&quot;], na.rm = TRUE) m.Y0m ## [1] 9 m.Y0f &lt;- mean(small.data$Y0[small.data$sex == &quot;Female&quot;], na.rm = TRUE) m.Y0f ## [1] 22 m.TE.m &lt;- m.Y1m-m.Y0m m.TE.f &lt;- m.Y1f-m.Y0f mean.values.m &lt;- c(NA,&quot;Mean for males&quot;, NA, round(c(m.Y1m, m.Y0m, m.TE.m),1)) mean.values.f &lt;- c(NA,&quot;Mean for females&quot;, NA, round(c(m.Y1f, m.Y0f, m.TE.f),1)) small.data$Y1[small.data$sex == &quot;Male&quot;][is.na(small.data$Y1[small.data$sex == &quot;Male&quot;])] &lt;- round(m.Y1m,1) small.data$Y0[small.data$sex == &quot;Male&quot;][is.na(small.data$Y0[small.data$sex == &quot;Male&quot;])] &lt;- round(m.Y0m,1) small.data$Y1[small.data$sex == &quot;Female&quot;][is.na(small.data$Y1[small.data$sex == &quot;Female&quot;])] &lt;- round(m.Y1f,1) small.data$Y0[small.data$sex == &quot;Female&quot;][is.na(small.data$Y0[small.data$sex == &quot;Female&quot;])] &lt;- round(m.Y0f,1) small.data$TE &lt;- small.data$Y1 - small.data$Y0 small.data2 &lt;- rbind(small.data, mean.values.m,mean.values.f) small.data2$Y1[1] &lt;- cell_spec(round(m.Y1m,1), bold = TRUE, color = &quot;red&quot;, background = &quot;yellow&quot;) small.data2$Y0[5] &lt;- cell_spec(round(m.Y0m,1), bold = TRUE, color = &quot;red&quot;, background = &quot;yellow&quot;) small.data2$Y1[c(4,6)] &lt;- cell_spec(round(m.Y1f,1), bold = TRUE, color = &quot;blue&quot;, background = &quot;yellow&quot;) small.data2$Y0[c(2,3)] &lt;- cell_spec(round(m.Y0f,1), bold = TRUE, color = &quot;blue&quot;, background = &quot;yellow&quot;) kable(small.data2, booktabs = TRUE, digits=1, escape = FALSE, col.names = c(&quot;Subject ID&quot;,&quot;Sex&quot;,&quot;RHC status (A)&quot;, &quot;Y when A=1 (RHC)&quot;, &quot;Y when A=0 (no RHC)&quot;, &quot;Treatment Effect&quot;))%&gt;% row_spec(7, bold = TRUE, color = &quot;white&quot;, background = &quot;red&quot;)%&gt;% row_spec(8, bold = TRUE, color = &quot;white&quot;, background = &quot;blue&quot;) Subject ID Sex RHC status (A) Y when A=1 (RHC) Y when A=0 (no RHC) Treatment Effect John Male 0 2 9 -7 Emma Female 1 45 22 23 Isabella Female 1 60 22 38 Sophia Female 0 52.5 37 15.5 Luke Male 1 2 9 -7 Mia Female 0 52.5 7 45.5 Mean for males 2 9 -7 Mean for females 52.5 22 30.5 Extending the problem to other covariates, you can see that we could condition on rest of the covariates (such as age, income, race, disease category) to get better imputation values. Regression is a generalized method to take mean conditional on many covariates. 2.2 Use Regression for predicting outcome Let us fit the outcome with all covariates, including the exposure status. # isolate the names of baseline covariates baselinevars &lt;- names(dplyr::select(ObsData, !c(A,Y))) # adjust the exposure variable (primary interest) + covariates out.formula &lt;- as.formula(paste(&quot;Y~ A +&quot;, paste(baselinevars, collapse = &quot;+&quot;))) fit1 &lt;- lm(out.formula, data = ObsData) coef(fit1) ## (Intercept) A ## -7.680847e+01 2.902030e+00 ## Disease.categoryCHF Disease.categoryOther ## -5.594331e+00 -4.421893e+00 ## Disease.categoryMOSF CancerLocalized (Yes) ## 2.873451e+00 -7.794459e+00 ## CancerMetastatic Cardiovascular1 ## -1.056549e+01 6.605038e-01 ## Congestive.HF1 Dementia1 ## -1.754818e+00 -1.261136e+00 ## Psychiatric1 Pulmonary1 ## -4.841489e-01 2.063282e+00 ## Renal1 Hepatic1 ## -6.935923e+00 -1.523238e+00 ## GI.Bleed1 Tumor1 ## -5.096253e+00 4.573818e+00 ## Immunosupperssion1 Transfer.hx1 ## 1.103694e-01 1.161342e+00 ## MI1 age[50,60) ## -1.650935e+00 1.429833e-01 ## age[60,70) age[70,80) ## -4.055267e-01 -1.103439e+00 ## age[80, Inf) sexFemale ## -2.757278e+00 8.272236e-01 ## edu DASIndex ## 4.775891e-02 -5.343588e-02 ## APACHE.score Glasgow.Coma.Score ## -7.020692e-02 1.563055e-02 ## blood.pressure WBC ## -1.323182e-02 3.940879e-02 ## Heart.rate Respiratory.rate ## 2.244431e-02 -1.467861e-03 ## Temperature PaO2vs.FIO2 ## 5.086475e-01 -8.517735e-03 ## Albumin Hematocrit ## -2.570965e+00 -1.951544e-01 ## Bilirubin Creatinine ## -9.814574e-02 5.210509e-01 ## Sodium Potassium ## 1.365534e-01 3.447162e-01 ## PaCo2 PH ## 1.165866e-01 1.005261e+01 ## Weight DNR.statusYes ## 2.257116e-04 -7.959037e+00 ## Medical.insuranceMedicare Medical.insuranceMedicare &amp; Medicaid ## -5.174593e-01 -2.422199e+00 ## Medical.insuranceNo insurance Medical.insurancePrivate ## -1.785085e+00 -2.086480e+00 ## Medical.insurancePrivate &amp; Medicare Respiratory.DiagYes ## -2.018369e+00 3.404743e-01 ## Cardiovascular.DiagYes Neurological.DiagYes ## 3.784972e-01 3.541516e+00 ## Gastrointestinal.DiagYes Renal.DiagYes ## 2.551541e+00 1.784893e+00 ## Metabolic.DiagYes Hematologic.DiagYes ## -1.161415e+00 -3.858024e+00 ## Sepsis.DiagYes Trauma.DiagYes ## 2.716148e-03 1.112049e+00 ## Orthopedic.DiagYes raceblack ## 3.543464e+00 -1.149936e+00 ## raceother income$25-$50k ## 2.467487e-01 2.459547e+00 ## income&gt; $50k incomeUnder $11k ## 4.214815e-01 -4.284414e-01 2.2.1 Predict outcome for treated Using the regression fit, we can obtain predicted outcome values for the treated. We are not only predicting for the unobserved, but also for the observed values when a person was treated. ObsData$Pred.Y1 &lt;- predict(fit1, newdata = data.frame(A = 1, dplyr::select(ObsData, !A)), type = &quot;response&quot;) Mean predicted outcome for treated mean(ObsData$Pred.Y1) ## [1] 23.35625 hist(ObsData$Pred.Y1, main = &quot;Histogram for predicted outcome for treated&quot;, xlab = &quot;Y(A=1)&quot;) abline(v=mean(ObsData$Pred.Y1),col=&quot;blue&quot;, lwd = 4) 2.2.2 Look at the predicted outcome data for treated small.data1 &lt;- ObsData[1:6,c(&quot;A&quot;,&quot;Pred.Y1&quot;)] small.data1$id &lt;- c(&quot;John&quot;,&quot;Emma&quot;,&quot;Isabella&quot;,&quot;Sophia&quot;,&quot;Luke&quot;, &quot;Mia&quot;) small.data1 &lt;- small.data1[c(&quot;id&quot;, &quot;A&quot;,&quot;Pred.Y1&quot;)] kable(small.data1, booktabs = TRUE, digits=1, col.names = c(&quot;id&quot;,&quot;RHC status (A)&quot;, &quot;Y.hat when A=1 (RHC)&quot;)) id RHC status (A) Y.hat when A=1 (RHC) John 0 17.5 Emma 1 28.7 Isabella 1 24.6 Sophia 0 21.6 Luke 1 13.6 Mia 0 25.5 2.2.3 Predict outcome for untreated ObsData$Pred.Y0 &lt;- predict(fit1, newdata = data.frame(A = 0, dplyr::select(ObsData, !A)), type = &quot;response&quot;) Mean predicted outcome for untreated mean(ObsData$Pred.Y0) ## [1] 20.45422 hist(ObsData$Pred.Y0, main = &quot;Histogram for predicted outcome for untreated&quot;, xlab = &quot;Y(A=0)&quot;) abline(v=mean(ObsData$Pred.Y0),col=&quot;blue&quot;, lwd = 4) 2.2.4 Look at the predicted outcome data for untreated small.data0 &lt;- ObsData[1:6,c(&quot;A&quot;,&quot;Pred.Y0&quot;)] small.data0$id &lt;- c(&quot;John&quot;,&quot;Emma&quot;,&quot;Isabella&quot;,&quot;Sophia&quot;,&quot;Luke&quot;, &quot;Mia&quot;) small.data0 &lt;- small.data0[c(&quot;id&quot;, &quot;A&quot;,&quot;Pred.Y0&quot;)] kable(small.data0, booktabs = TRUE, digits=1, col.names = c(&quot;id&quot;,&quot;RHC status (A)&quot;, &quot;Y.hat when A=0 (no RHC)&quot;)) id RHC status (A) Y.hat when A=0 (no RHC) John 0 14.6 Emma 1 25.8 Isabella 1 21.7 Sophia 0 18.7 Luke 1 10.7 Mia 0 22.6 2.2.5 Look at the predicted outcome data for all! small.data01 &lt;- small.data1 small.data01$Pred.Y0 &lt;- small.data0$Pred.Y0 small.data01$Pred.TE &lt;- small.data01$Pred.Y1 - small.data01$Pred.Y0 m.Y1 &lt;- mean(small.data01$Pred.Y1) m.Y0 &lt;- mean(small.data01$Pred.Y0) mean.values &lt;- round(c(NA,NA, m.Y1, m.Y0, m.Y1 -m.Y0),1) small.data2 &lt;- rbind(small.data01, mean.values) kable(small.data2, booktabs = TRUE, digits=1, col.names = c(&quot;id&quot;,&quot;RHC status (A)&quot;, &quot;Y.hat when A=1 (RHC)&quot;, &quot;Y.hat when A=0 (no RHC)&quot;, &quot;Treatment Effect&quot;))%&gt;% row_spec(7, bold = TRUE, color = &quot;white&quot;, background = &quot;#D7261E&quot;) id RHC status (A) Y.hat when A=1 (RHC) Y.hat when A=0 (no RHC) Treatment Effect John 0 17.5 14.6 2.9 Emma 1 28.7 25.8 2.9 Isabella 1 24.6 21.7 2.9 Sophia 0 21.6 18.7 2.9 Luke 1 13.6 10.7 2.9 Mia 0 25.5 22.6 2.9 21.9 19.0 2.9 From this table, it is easy to calculate treatment effect estimate. The process we just went through, is a version of parametric G-computation! 2.3 Parametric G-computation Figure 2.1: Defining treatment effect in terms of potential outcomes and observations 2.3.1 Steps Step 1 Fit the outcome regression on the exposure and covariates: \\(Y \\sim A + L\\) Step 2 Extract outcome prediction for treated \\(\\hat{Y}_{A=1}\\) by setting all \\(A=1\\) Step 3 Extract outcome prediction for untreated \\(\\hat{Y}_{A=0}\\) by setting all \\(A=0\\) Step 4 Subtract the mean of these two outcome predictions to get treatment effect estimate: \\(TE = E(\\hat{Y}_{A=1}) - E(\\hat{Y}_{A=0})\\) 2.3.1.1 Step 1 Fit the outcome regression on the exposure and covariates: \\(Y \\sim A + L\\) out.formula &lt;- as.formula(paste(&quot;Y~ A +&quot;, paste(baselinevars, collapse = &quot;+&quot;))) fit1 &lt;- lm(out.formula, data = ObsData) 2.3.1.2 Step 2 Extract outcome prediction for treated \\(\\hat{Y}_{A=1}\\) by setting all \\(A=1\\)| ObsData$Pred.Y1 &lt;- predict(fit1, newdata = data.frame(A = 1, dplyr::select(ObsData, !A)), type = &quot;response&quot;) 2.3.1.3 Step 3 Extract outcome prediction for untreated \\(\\hat{Y}_{A=0}\\) by setting all \\(A=0\\) ObsData$Pred.Y0 &lt;- predict(fit1, newdata = data.frame(A = 0, dplyr::select(ObsData, !A)), type = &quot;response&quot;) 2.3.1.4 Step 4 Subtract the mean of these two outcome predictions to get treatment effect estimate: \\(TE = E(\\hat{Y}_{A=1}) - E(\\hat{Y}_{A=0})\\) ObsData$Pred.TE &lt;- ObsData$Pred.Y1 - ObsData$Pred.Y0 2.3.2 Treatment effect estimate Mean value of predicted treatment effect TE &lt;- mean(ObsData$Pred.TE) TE ## [1] 2.90203 SD of treatment effect sd(ObsData$Pred.TE) ## [1] 5.132733e-15 hist(ObsData$Pred.TE, main = &quot;Histogram for predicted treatment effect&quot;, xlab = &quot;Y(A=1) - Y(A=0)&quot;) ## Warning in plot.window(xlim, ylim, &quot;&quot;, ...): relative range of values ( 93 * ## EPS) is small (axis 1) abline(v=mean(ObsData$Pred.TE),col=&quot;blue&quot;, lwd = 4) This shows that the SD estimate is useless from g-computation method directly. 2.4 Estimating the confidence intervals We already have an idea about the point estimate of the treatment effect: mean(ObsData$Pred.TE) ## [1] 2.90203 For confidence interval estimates for G-computation, bootstrap would be necessary. In the following example, we use \\(R = 250\\). require(boot) gcomp.boot &lt;- function(formula = out.formula, data = ObsData, indices) { boot_sample &lt;- data[indices, ] fit.boot &lt;- lm(formula, data = boot_sample) Pred.Y1 &lt;- predict(fit.boot, newdata = data.frame(A = 1, dplyr::select(boot_sample, !A)), type = &quot;response&quot;) Pred.Y0 &lt;- predict(fit.boot, newdata = data.frame(A = 0, dplyr::select(boot_sample, !A)), type = &quot;response&quot;) Pred.TE &lt;- mean(Pred.Y1) - mean(Pred.Y0) return(Pred.TE) } set.seed(123) gcomp.res &lt;- boot(data=ObsData, statistic=gcomp.boot, R=250, formula=out.formula) Below we show the resulting estimates from \\(R\\) bootstrap samples. plot(gcomp.res) Below are two versions of confidence interval. One is based on normality assumption: point estimate - and + with 1.96 multiplied by SD estimate Another is based on percentiles CI1 &lt;- boot.ci(gcomp.res, type=&quot;norm&quot;) CI1 ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 250 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = gcomp.res, type = &quot;norm&quot;) ## ## Intervals : ## Level Normal ## 95% ( 1.315, 4.444 ) ## Calculations and Intervals on Original Scale CI2 &lt;- boot.ci(gcomp.res, type=&quot;perc&quot;) CI2 ## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS ## Based on 250 bootstrap replicates ## ## CALL : ## boot.ci(boot.out = gcomp.res, type = &quot;perc&quot;) ## ## Intervals : ## Level Percentile ## 95% ( 1.515, 4.589 ) ## Calculations and Intervals on Original Scale ## Some percentile intervals may be unstable saveRDS(TE, file = &quot;data/gcomp.RDS&quot;) saveRDS(CI2, file = &quot;data/gcompci.RDS&quot;) "],["g-computation-using-ml.html", "Chapter 3 G-computation using ML 3.1 G-comp using Regression tree 3.2 G-comp using regularized methods 3.3 G-comp using SuperLearner", " Chapter 3 G-computation using ML G-computation is highly sensitive to on model misspecification; and when model is not correctly specified, result is subject to bias. Therefore, it can be a good idea to use machine learning methods, that are more flexible, than parametric methods to estimate the treatment effect. Although ML methods are powerful in point estimation, the coverage probabilities are usually poor when more flexible methods are used, if inference is one of the goals. Hence we are focusing on point estimation here. 3.1 G-comp using Regression tree # Read the data saved at the last chapter ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) baselinevars &lt;- names(dplyr::select(ObsData, !A)) out.formula &lt;- as.formula(paste(&quot;Y~ A +&quot;, paste(baselinevars, collapse = &quot;+&quot;))) 3.1.1 A tree based algorithm XGBoost is a fast version of gradient boosting algorithm. Let us use this one to fit the data first. We follow the exact same procedure that we followed in the parametric G-computation setting. require(xgboost) Y &lt;-ObsData$Y ObsData.matrix &lt;- model.matrix(out.formula, data = ObsData) fit3 &lt;- xgboost(data = ObsData.matrix, label = Y, max.depth = 10, eta = 1, nthread = 15, nrounds = 100, alpha = 0.5, objective = &quot;reg:squarederror&quot;, verbose = 0) predY &lt;- predict(fit3, newdata = ObsData.matrix) plot(density(Y), col = &quot;red&quot;, main = &quot;Predicted and observed Y&quot;, xlim = c(1,100)) legend(&quot;topright&quot;, c(&quot;Y&quot;,&quot;Predicted Y&quot;), lty = c(1,2), col = c(&quot;red&quot;,&quot;blue&quot;)) lines(density(predY), col = &quot;blue&quot;, lty = 2) caret::RMSE(predY,Y) ## [1] 0.01255211 What we have done here is we have used the ObsData.matrix data to train our model, and we have used newdata = ObsData.matrix to obtain prediction. When we use same model for training and obtaining prediction, often the predictions are highly optimistic (RMSE is unrealistically low for future predictions), and we call this a over-fitting problem. One way to deal with this problem is called Cross-validation. 3.1.2 Cross-validation Cross-validation means splitting the data into training data testing data In each iteration: (1) Fitting models in training data (2) obtaining prediction \\(\\hat{Y}\\) in test data (3) obtain all RMSEs from each iteration, and (4) average all RMSEs. Figure 3.1: Cross validation from wiki; training data = used for building model; test data = used for prediction from the model that was built using training data; each iteration = fold 3.1.2.1 Cross-validation using caret We use caret package to do cross-validation. caret is a general framework package for machine learning that can also incorporate other ML approaches such as xgboost. require(caret) set.seed(123) X_ObsData.matrix &lt;- xgb.DMatrix(ObsData.matrix) Y_ObsData &lt;- ObsData$Y Below we define \\(K = 3\\) for cross-validation. Ideally for a sample size close to \\(n=5,000\\), we would select \\(K=10\\), but for learning / demonstration / computational time-saving purposes, we just use \\(K = 3\\). xgb_trcontrol = trainControl( method = &quot;cv&quot;, number = 3, allowParallel = TRUE, verboseIter = FALSE, returnData = FALSE ) 3.1.2.2 Fine tuning One of the advantages of caret framework is that, it also allows checking the impact of various parameters (can do fine tuning). For example, for interaction depth, we previously use max.depth = 10. That means \\(covariate^{10}\\) polynomial. We could also check if other interaction depth choices (such as \\(covariate^{2}\\) or \\(covariate^{4}\\)) would be better in terms of honest predictions. xgbGrid &lt;- expand.grid( nrounds = 100, max_depth = seq(2,10,2), eta = 1, gamma = 0, colsample_bytree = 0.1, min_child_weight = 2, subsample = 0.5 ) 3.1.2.3 Fit model with CV once we set resampling or cross-validation settings parameter grid we can fit the model: fit.xgb &lt;- train( X_ObsData.matrix, Y_ObsData, trControl = xgb_trcontrol, method = &quot;xgbTree&quot;, tuneGrid = xgbGrid, verbose = FALSE ) fit.xgb ## eXtreme Gradient Boosting ## ## No pre-processing ## Resampling: Cross-Validated (3 fold) ## Summary of sample sizes: 3822, 3824, 3824 ## Resampling results across tuning parameters: ## ## max_depth RMSE Rsquared MAE ## 2 28.87561 0.020524186 19.08176 ## 4 38.88354 0.007198028 28.08175 ## 6 49.62373 0.002200636 37.69929 ## 8 54.86092 0.004255366 42.40188 ## 10 57.13972 0.001224946 44.15276 ## ## Tuning parameter &#39;nrounds&#39; was held constant at a value of 100 ## Tuning ## held constant at a value of 2 ## Tuning parameter &#39;subsample&#39; was held ## constant at a value of 0.5 ## RMSE was used to select the optimal model using the smallest value. ## The final values used for the model were nrounds = 100, max_depth = 2, eta = ## 1, gamma = 0, colsample_bytree = 0.1, min_child_weight = 2 and subsample = 0.5. Based on the loss function (say, RMSE) it automatically chose the best tuning parameter set: fit.xgb$bestTune$max_depth ## [1] 2 predY &lt;- predict(fit.xgb, newdata = ObsData.matrix) plot(density(Y), col = &quot;red&quot;, main = &quot;Predicted and observed Y&quot;, xlim = c(1,100)) legend(&quot;topright&quot;, c(&quot;Y&quot;,&quot;Predicted Y&quot;), lty = c(1,2), col = c(&quot;red&quot;,&quot;blue&quot;)) lines(density(predY), col = &quot;blue&quot;, lty = 2) caret::RMSE(predY,Y) ## [1] 24.35099 3.1.3 G-comp step 2: Extract outcome prediction as if everyone is treated ObsData.matrix.A1 &lt;- ObsData.matrix ObsData.matrix.A1[,&quot;A&quot;] &lt;- 1 ObsData$Pred.Y1 &lt;- predict(fit.xgb, newdata = ObsData.matrix.A1) summary(ObsData$Pred.Y1) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -33.15 14.87 23.09 23.89 31.78 131.48 3.1.4 G-comp step 3: Extract outcome prediction as if everyone is untreated ObsData.matrix.A0 &lt;- ObsData.matrix ObsData.matrix.A0[,&quot;A&quot;] &lt;- 0 ObsData$Pred.Y0 &lt;- predict(fit.xgb, newdata = ObsData.matrix.A0) summary(ObsData$Pred.Y0) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -37.31 10.72 18.96 19.78 27.69 127.31 3.1.5 G-comp step 4: Treatment effect estimate ObsData$Pred.TE &lt;- ObsData$Pred.Y1 - ObsData$Pred.Y0 Mean value of predicted treatment effect TE1 &lt;- mean(ObsData$Pred.TE) TE1 ## [1] 4.110383 summary(ObsData$Pred.TE) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -5.494 4.165 4.165 4.110 4.165 9.339 Notice that the mean is slightly different than the parametric G-computation method. 3.2 G-comp using regularized methods 3.2.1 A regularized model LASSO is a regularized method. One of the uses of these methods is variable selection or addressing concerns of multicollinearity. Let us use this method to fit our data. We are again using cross-validation here, and we chose \\(K=3\\). require(glmnet) Y &lt;-ObsData$Y ObsData.matrix &lt;- model.matrix(out.formula, data = ObsData) fit4 &lt;- cv.glmnet(x = ObsData.matrix, y = Y, alpha = 1, nfolds = 3, relax=TRUE) 3.2.2 G-comp step 2: Extract outcome prediction as if everyone is treated ObsData.matrix.A1 &lt;- ObsData.matrix ObsData.matrix.A1[,&quot;A&quot;] &lt;- 1 ObsData$Pred.Y1 &lt;- predict(fit4, newx = ObsData.matrix.A1, s = &quot;lambda.min&quot;) summary(ObsData$Pred.Y1) ## lambda.min ## Min. :-30.41 ## 1st Qu.: 19.53 ## Median : 23.95 ## Mean : 23.24 ## 3rd Qu.: 27.26 ## Max. : 38.14 3.2.3 G-comp step 3: Extract outcome prediction as if everyone is untreated ObsData.matrix.A0 &lt;- ObsData.matrix ObsData.matrix.A0[,&quot;A&quot;] &lt;- 0 ObsData$Pred.Y0 &lt;- predict(fit4, newx = ObsData.matrix.A0, s = &quot;lambda.min&quot;) summary(ObsData$Pred.Y0) ## lambda.min ## Min. :-33.13 ## 1st Qu.: 16.81 ## Median : 21.23 ## Mean : 20.52 ## 3rd Qu.: 24.54 ## Max. : 35.42 3.2.4 G-comp step 3: Treatment effect estimate ObsData$Pred.TE &lt;- ObsData$Pred.Y1 - ObsData$Pred.Y0 Mean value of predicted treatment effect TE2 &lt;- mean(ObsData$Pred.TE) TE2 ## [1] 2.719739 summary(ObsData$Pred.TE) ## lambda.min ## Min. :2.72 ## 1st Qu.:2.72 ## Median :2.72 ## Mean :2.72 ## 3rd Qu.:2.72 ## Max. :2.72 Notice that the mean is very similar to the parametric G-computation method. 3.3 G-comp using SuperLearner SuperLearner is an ensemble MLtechnique, that uses cross-validation to find a weighted combination of estimates provided by different candidate learners (that help predict). There exists many candidate learners. Here we are using a combination of linear regression Regularized regression (lasso) gradient boosting (tree based) 3.3.1 Steps Step 1 Identify candidate learners Step 2 Choose Cross-validation K Step 3 Select loss function for meta learner Step 4 Find SL prediction: (1) Discrete SL (2) Ensamble SL 3.3.1.1 Identify candidate learners Choose variety of candidate learners parametric (linear or logistic regression) regularized (LASSO, ridge, elasticnet) stepwise non-parametric transformation (SVM, NN) tree based (bagging, boosting) smoothing or spline (gam) tune the candidate learners for better performance tree depth tune regularization parameters variable selection SL.library.chosen=c(&quot;SL.glm&quot;, &quot;SL.glmnet&quot;, &quot;SL.xgboost&quot;) SuperLearner is an ensemble learning method. Let us use this one to fit the data first. 3.3.1.2 Choose Cross-validation K To combat against optimism, we use cross-validation. SuperLearner first splits the data according to chosen \\(K\\) fold for the cross-validation. cvControl.chosen = list(V = 3) 3.3.1.3 Select loss function for meta learner and estimate risk The goal is to minimize the estimated risk (i.e., minimize the difference of \\(Y\\) and \\(\\hat{Y}\\)) that comes out of a model. We can chose a (non-negative) least squares loss function for the meta learner (explained below): loss.chosen = &quot;method.NNLS&quot; 3.3.1.4 Find SL prediction We first fit the super learner: require(SuperLearner) ObsData.noY &lt;- dplyr::select(ObsData, !Y) fit.sl &lt;- SuperLearner(Y=ObsData$Y, X=ObsData.noY, cvControl = cvControl.chosen, SL.library=SL.library.chosen, method=loss.chosen, family=&quot;gaussian&quot;) We can also obtain the predictions from each candidate learners. all.pred &lt;- predict(fit.sl, type = &quot;response&quot;) Yhat &lt;- all.pred$library.predict head(Yhat) ## SL.glm_All SL.glmnet_All SL.xgboost_All ## 1 14.61647 14.57121 14.890952 ## 2 28.66305 28.96897 42.775368 ## 3 24.57800 24.98479 49.592552 ## 4 18.70422 19.20871 25.078993 ## 5 13.64956 12.18804 8.819989 ## 6 22.56895 21.60971 11.892698 We can obtain the \\(K\\)-fold cross-validated risk estimates for each candidate learners. fit.sl$cvRisk ## SL.glm_All SL.glmnet_All SL.xgboost_All ## 634.4393 622.8681 737.5505 Once we have the performance measures and predictions from candidate learners, we could go one of two routes here 3.3.1.4.1 Discrete SL Get measure of performance from all folds are averaged, and choose the best one. The prediction from the chosen learners are then used. glmnet has the lowest cross-validated risk lowest.risk.learner &lt;- names(which( fit.sl$cvRisk == min(fit.sl$cvRisk))) lowest.risk.learner ## [1] &quot;SL.glmnet_All&quot; as.matrix(head(Yhat[,lowest.risk.learner]), ncol=1) ## [,1] ## 1 14.57121 ## 2 28.96897 ## 3 24.98479 ## 4 19.20871 ## 5 12.18804 ## 6 21.60971 3.3.1.4.2 Ensamble SL Here are the first 6 rows from the candidate learner predictions: head(Yhat) ## SL.glm_All SL.glmnet_All SL.xgboost_All ## 1 14.61647 14.57121 14.890952 ## 2 28.66305 28.96897 42.775368 ## 3 24.57800 24.98479 49.592552 ## 4 18.70422 19.20871 25.078993 ## 5 13.64956 12.18804 8.819989 ## 6 22.56895 21.60971 11.892698 fit a meta learner (optimal weighted combination; below is a simplified description) using linear regression (without intercept, but could produce -ve coefs) or preferably non-negative least squares for \\(Y_{obs}\\) \\(\\sim\\) \\(\\hat{Y}_{SL.glm}\\) + \\(\\hat{Y}_{SL.glmnet}\\) + \\(\\hat{Y}_{SL.xgboost}\\). Obtain the regression coefs \\(\\mathbf{\\beta}\\) = (\\(\\beta_{SL.glm}\\), \\(\\beta_{SL.glmnet}\\), \\(\\beta_{SL.xgboost}\\)) for each \\(\\hat{Y}\\), scale them to 1 \\(\\mathbf{\\beta_{scaled}}\\) = \\(\\mathbf{\\beta}\\) / \\(\\sum_{i=1}^3{\\mathbf{\\beta}}\\); so that the sum of scaled coefs = 1 Scaled coefficients \\(\\mathbf{\\beta_{scaled}}\\) represents the value / importance of the corresponding candidate learner. Scaled coefs fit.sl$coef ## SL.glm_All SL.glmnet_All SL.xgboost_All ## 0.00000000 0.93740912 0.06259088 Hence, in creating superlearner prediction column, Linear regression has no contribution lasso has majority contribution gradient boosting of tree has some minimal contribution A new prediction column is produced based on the fitted values from this meta regression. You can simply multiply these coefs to the predictions from candidate learners, and them sum them to get ensable SL. Here are the first 6 values: SL.ens &lt;- t(t(Yhat)*fit.sl$coef) head(SL.ens) ## SL.glm_All SL.glmnet_All SL.xgboost_All ## 1 0 13.65919 0.9320378 ## 2 0 27.15577 2.6773480 ## 3 0 23.42097 3.1040416 ## 4 0 18.00642 1.5697163 ## 5 0 11.42518 0.5520509 ## 6 0 20.25714 0.7443745 as.matrix(head(rowSums(SL.ens)), ncol = 1) ## [,1] ## 1 14.59123 ## 2 29.83312 ## 3 26.52501 ## 4 19.57614 ## 5 11.97723 ## 6 21.00152 Alternatively, you can get them directly from the package: here are the first 6 values head(all.pred$pred) ## [,1] ## 1 14.59123 ## 2 29.83312 ## 3 26.52501 ## 4 19.57614 ## 5 11.97723 ## 6 21.00152 The last column is coming from Ensamble SL. 3.3.2 G-comp step 2: Extract outcome prediction as if everyone is treated We are going to use Ensamble SL predictions in the following calculations. If you wanted to use discrete SL predictions instead, that would be fine too. ObsData.noY$A &lt;- 1 ObsData$Pred.Y1 &lt;- predict(fit.sl, newdata = ObsData.noY, type = &quot;response&quot;)$pred ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading summary(ObsData$Pred.Y1) ## V1 ## Min. :-31.15 ## 1st Qu.: 18.70 ## Median : 23.40 ## Mean : 22.75 ## 3rd Qu.: 27.09 ## Max. : 58.48 3.3.3 G-comp step 3: Extract outcome prediction as if everyone is untreated ObsData.noY$A &lt;- 0 ObsData$Pred.Y0 &lt;- predict(fit.sl, newdata = ObsData.noY, type = &quot;response&quot;)$pred ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading summary(ObsData$Pred.Y0) ## V1 ## Min. :-33.10 ## 1st Qu.: 16.76 ## Median : 21.50 ## Mean : 20.83 ## 3rd Qu.: 25.18 ## Max. : 55.86 3.3.4 G-comp step 3: Treatment effect estimate ObsData$Pred.TE &lt;- ObsData$Pred.Y1 - ObsData$Pred.Y0 Mean value of predicted treatment effect TE3 &lt;- mean(ObsData$Pred.TE) TE3 ## [1] 1.914702 summary(ObsData$Pred.TE) ## V1 ## Min. :1.099 ## 1st Qu.:1.849 ## Median :1.907 ## Mean :1.915 ## 3rd Qu.:1.976 ## Max. :2.991 3.3.5 Additional details for SL 3.3.5.1 Choice of K simplest cross-validation splits the data into \\(K=2\\) parts, but can go higher. select \\(K\\) judiciously large sample size means small \\(K\\) may be adequate for \\(n \\lt 10,000\\) consider \\(K=3\\) for \\(n \\lt 500\\) consider \\(K=20\\) smaller sample size means larger \\(K\\) may be necessary for \\(n \\lt 30\\) consider leave 1 out 3.3.5.2 Alternative to CV other similar algorithms such as cross-fitting had been shown to have better performances 3.3.5.3 Rare outcome for rare outcomes, consider using stratification to attempt to maintain training and test sample ratios the same 3.3.5.4 Dependant sample if data is clustered and not independent and identically distributed, use ID for the cluster 3.3.5.5 Choice of meta learner method It is easy to show that, depending on the choice of meta-learners, the coefficients of the meta learners can be slightly different. fit.sl2 &lt;- recombineSL(fit.sl, Y = Y, method = &quot;method.NNLS2&quot;) fit.sl2$coef ## SL.glm_All SL.glmnet_All SL.xgboost_All ## 0.00000000 0.93740912 0.06259088 fit.sl2 &lt;- recombineSL(fit.sl, Y = Y, method = &quot;method.CC_LS&quot;) fit.sl2$coef ## SL.glm_All SL.glmnet_All SL.xgboost_All ## 0.00000000 0.93662601 0.06337399 fit.sl4 &lt;- recombineSL(fit.sl, Y = Y, method = &quot;method.CC_nloglik&quot;) fit.sl4$coef ## SL.glm_All SL.glmnet_All SL.xgboost_All ## 0 1 0 method.CC_LS is suggested as a good method for continuous outcome method.CC_nloglik is suggested as a good method for binary outcome saveRDS(TE1, file = &quot;data/gcompxg.RDS&quot;) saveRDS(TE2, file = &quot;data/gcompls.RDS&quot;) saveRDS(TE3, file = &quot;data/gcompsl.RDS&quot;) "],["iptw.html", "Chapter 4 IPTW 4.1 IPTW steps 4.2 Step 1: exposure modelling 4.3 Step 2: Convert PS to IPW 4.4 Step 3: Balance checking 4.5 Step 4: outcome modelling", " Chapter 4 IPTW In this chapter, we are primarily interested about exposure modelling (e.g., fixing imbalance first, before doing outcome analysis). # Read the data saved at the last chapter ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) baselinevars &lt;- names(dplyr::select(ObsData, !c(A,Y))) 4.1 IPTW steps Modelling Steps: According to Austin (2011), we need to follow 4 steps: Step 1 exposure modelling: \\(PS = Prob(A=1|L)\\) Step 2 Convert \\(PS\\) to \\(IPW\\) = \\(\\frac{A}{PS} + \\frac{1-A}{1-PS}\\) Step 3 Assess balance in weighted sample (\\(PS\\) and \\(L\\)) Step 4 outcome modelling: \\(E(Y|A=1)\\) to obtain treatment effect estimate 4.2 Step 1: exposure modelling Exposure modelling: \\(PS = Prob(A=1|L)\\) ps.formula &lt;- as.formula(paste(&quot;A ~&quot;, paste(baselinevars, collapse = &quot;+&quot;))) ps.formula ## A ~ Disease.category + Cancer + Cardiovascular + Congestive.HF + ## Dementia + Psychiatric + Pulmonary + Renal + Hepatic + GI.Bleed + ## Tumor + Immunosupperssion + Transfer.hx + MI + age + sex + ## edu + DASIndex + APACHE.score + Glasgow.Coma.Score + blood.pressure + ## WBC + Heart.rate + Respiratory.rate + Temperature + PaO2vs.FIO2 + ## Albumin + Hematocrit + Bilirubin + Creatinine + Sodium + ## Potassium + PaCo2 + PH + Weight + DNR.status + Medical.insurance + ## Respiratory.Diag + Cardiovascular.Diag + Neurological.Diag + ## Gastrointestinal.Diag + Renal.Diag + Metabolic.Diag + Hematologic.Diag + ## Sepsis.Diag + Trauma.Diag + Orthopedic.Diag + race + income Other than main effect terms, what other model specifications are possible? Common terms to add (indeed based on biological plausibility; requiring subject area knowledge) Interactions polynomials or splines transformations Fit logistic regression to estimate propensity scores PS.fit &lt;- glm(ps.formula,family=&quot;binomial&quot;, data=ObsData) require(Publish) publish(PS.fit, format = &quot;[u;l]&quot;) ## Variable Units OddsRatio CI.95 p-value ## Disease.category ARF Ref ## CHF 1.79 [1.32;2.43] 0.0002047 ## Other 0.54 [0.43;0.68] &lt; 1e-04 ## MOSF 1.58 [1.34;1.87] &lt; 1e-04 ## Cancer None Ref ## Localized (Yes) 0.46 [0.22;0.96] 0.0389310 ## Metastatic 0.37 [0.17;0.81] 0.0131229 ## Cardiovascular 0 Ref ## 1 1.04 [0.86;1.25] 0.7036980 ## Congestive.HF 0 Ref ## 1 1.10 [0.90;1.35] 0.3461245 ## Dementia 0 Ref ## 1 0.67 [0.53;0.85] 0.0011382 ## Psychiatric 0 Ref ## 1 0.65 [0.50;0.85] 0.0018616 ## Pulmonary 0 Ref ## 1 0.97 [0.81;1.18] 0.7814947 ## Renal 0 Ref ## 1 0.70 [0.49;1.00] 0.0523978 ## Hepatic 0 Ref ## 1 0.79 [0.57;1.11] 0.1817681 ## GI.Bleed 0 Ref ## 1 0.76 [0.49;1.17] 0.2148665 ## Tumor 0 Ref ## 1 1.48 [0.71;3.12] 0.2987694 ## Immunosupperssion 0 Ref ## 1 1.00 [0.86;1.15] 0.9778387 ## Transfer.hx 0 Ref ## 1 1.46 [1.20;1.77] 0.0001356 ## MI 0 Ref ## 1 1.12 [0.80;1.59] 0.5031463 ## age [-Inf,50) Ref ## [50,60) 1.04 [0.85;1.27] 0.7327200 ## [60,70) 1.22 [1.00;1.49] 0.0559205 ## [70,80) 1.15 [0.91;1.45] 0.2414163 ## [80, Inf) 0.66 [0.49;0.89] 0.0054612 ## sex Male Ref ## Female 0.98 [0.86;1.12] 0.7661356 ## edu 1.03 [1.01;1.05] 0.0101741 ## DASIndex 1.00 [0.98;1.01] 0.6635060 ## APACHE.score 1.01 [1.01;1.02] &lt; 1e-04 ## Glasgow.Coma.Score 1.00 [1.00;1.00] 0.2853053 ## blood.pressure 0.99 [0.99;0.99] &lt; 1e-04 ## WBC 1.00 [0.99;1.00] 0.7368619 ## Heart.rate 1.00 [1.00;1.01] &lt; 1e-04 ## Respiratory.rate 0.98 [0.97;0.98] &lt; 1e-04 ## Temperature 0.97 [0.93;1.01] 0.1255016 ## PaO2vs.FIO2 0.99 [0.99;1.00] &lt; 1e-04 ## Albumin 0.93 [0.85;1.02] 0.1032557 ## Hematocrit 0.99 [0.98;1.00] 0.0103236 ## Bilirubin 1.01 [1.00;1.02] 0.1719966 ## Creatinine 1.04 [1.00;1.09] 0.0576310 ## Sodium 0.99 [0.98;1.00] 0.0049192 ## Potassium 0.85 [0.79;0.91] &lt; 1e-04 ## PaCo2 0.98 [0.97;0.98] &lt; 1e-04 ## PH 0.22 [0.11;0.47] &lt; 1e-04 ## Weight 1.01 [1.00;1.01] &lt; 1e-04 ## DNR.status No Ref ## Yes 0.58 [0.46;0.73] &lt; 1e-04 ## Medical.insurance Medicaid Ref ## Medicare 1.34 [1.03;1.74] 0.0315228 ## Medicare &amp; Medicaid 1.49 [1.07;2.07] 0.0184712 ## No insurance 1.66 [1.20;2.30] 0.0023684 ## Private 1.55 [1.21;1.97] 0.0004402 ## Private &amp; Medicare 1.46 [1.11;1.92] 0.0071028 ## Respiratory.Diag No Ref ## Yes 0.76 [0.65;0.90] 0.0010144 ## Cardiovascular.Diag No Ref ## Yes 1.80 [1.52;2.13] &lt; 1e-04 ## Neurological.Diag No Ref ## Yes 0.62 [0.47;0.80] 0.0002731 ## Gastrointestinal.Diag No Ref ## Yes 1.41 [1.15;1.73] 0.0010690 ## Renal.Diag No Ref ## Yes 1.35 [1.01;1.80] 0.0461405 ## Metabolic.Diag No Ref ## Yes 0.85 [0.63;1.15] 0.2953120 ## Hematologic.Diag No Ref ## Yes 0.59 [0.45;0.78] 0.0002225 ## Sepsis.Diag No Ref ## Yes 1.31 [1.10;1.57] 0.0029968 ## Trauma.Diag No Ref ## Yes 3.45 [1.80;6.64] 0.0002014 ## Orthopedic.Diag No Ref ## Yes 3.74 [0.53;26.25] 0.1843027 ## race white Ref ## black 1.05 [0.87;1.26] 0.6250189 ## other 1.09 [0.84;1.41] 0.5272282 ## income $11-$25k Ref ## $25-$50k 1.08 [0.87;1.34] 0.4644703 ## &gt; $50k 1.02 [0.78;1.34] 0.8810245 ## Under $11k 1.06 [0.90;1.26] 0.4797051 Coef of PS model fit is not of concern Model can be rich: to the extent that prediction is better But look for multi-collinearity issues SE too high? Obtain the propesnity score (PS) values from the fit ObsData$PS &lt;- predict(PS.fit, type=&quot;response&quot;) Check summaries: enough overlap? PS values very close to 0 or 1? summary(ObsData$PS) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.002478 0.161446 0.358300 0.380819 0.574319 0.968425 tapply(ObsData$PS, ObsData$A, summary) ## $`0` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.002478 0.106718 0.241301 0.283816 0.427138 0.951927 ## ## $`1` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.01575 0.37205 0.55243 0.53854 0.70999 0.96842 plot(density(ObsData$PS[ObsData$A==0]), col = &quot;red&quot;, main = &quot;&quot;) lines(density(ObsData$PS[ObsData$A==1]), col = &quot;blue&quot;, lty = 2) legend(&quot;topright&quot;, c(&quot;No RHC&quot;,&quot;RHC&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty=1:2) 4.3 Step 2: Convert PS to IPW Convert \\(PS\\) to \\(IPW\\) = \\(\\frac{A}{PS} + \\frac{1-A}{1-PS}\\) Convert PS to IPW using the formula. We are using the formula for average treatment effect (ATE). It is possible to use alternative formulas, but we are using ATE formula for our illustration. ObsData$IPW &lt;- ObsData$A/ObsData$PS + (1-ObsData$A)/(1-ObsData$PS) summary(ObsData$IPW) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.002 1.183 1.472 1.986 2.064 63.509 Also possible to use pre-packged software packages to do the same: require(WeightIt) W.out &lt;- weightit(ps.formula, data = ObsData, estimand = &quot;ATE&quot;, method = &quot;ps&quot;) summary(W.out$weights) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.002 1.183 1.472 1.986 2.064 63.509 4.4 Step 3: Balance checking Assess balance in weighted sample (\\(PS\\) and \\(L\\)) We can check balance numerically. We set SMD = 0.1 as threshold for balance. \\(SMD \\gt 0.1\\) means we do not have balance require(cobalt) bal.tab(W.out, un = TRUE, thresholds = c(m = .1)) ## Call ## weightit(formula = ps.formula, data = ObsData, method = &quot;ps&quot;, ## estimand = &quot;ATE&quot;) ## ## Balance Measures ## Type Diff.Un Diff.Adj M.Threshold ## prop.score Distance 1.1926 0.0224 Balanced, &lt;0.1 ## Disease.category_ARF Binary -0.0290 0.0025 Balanced, &lt;0.1 ## Disease.category_CHF Binary 0.0261 0.0008 Balanced, &lt;0.1 ## Disease.category_Other Binary -0.1737 -0.0080 Balanced, &lt;0.1 ## Disease.category_MOSF Binary 0.1766 0.0047 Balanced, &lt;0.1 ## Cancer_None Binary 0.0439 0.0017 Balanced, &lt;0.1 ## Cancer_Localized (Yes) Binary -0.0267 0.0017 Balanced, &lt;0.1 ## Cancer_Metastatic Binary -0.0172 -0.0034 Balanced, &lt;0.1 ## Cardiovascular Binary 0.0445 0.0051 Balanced, &lt;0.1 ## Congestive.HF Binary 0.0268 0.0013 Balanced, &lt;0.1 ## Dementia Binary -0.0472 -0.0138 Balanced, &lt;0.1 ## Psychiatric Binary -0.0348 -0.0050 Balanced, &lt;0.1 ## Pulmonary Binary -0.0737 -0.0058 Balanced, &lt;0.1 ## Renal Binary 0.0066 0.0027 Balanced, &lt;0.1 ## Hepatic Binary -0.0124 -0.0012 Balanced, &lt;0.1 ## GI.Bleed Binary -0.0122 -0.0026 Balanced, &lt;0.1 ## Tumor Binary -0.0423 -0.0016 Balanced, &lt;0.1 ## Immunosupperssion Binary 0.0358 -0.0027 Balanced, &lt;0.1 ## Transfer.hx Binary 0.0554 0.0047 Balanced, &lt;0.1 ## MI Binary 0.0139 0.0005 Balanced, &lt;0.1 ## age_[-Inf,50) Binary -0.0017 -0.0098 Balanced, &lt;0.1 ## age_[50,60) Binary 0.0161 0.0149 Balanced, &lt;0.1 ## age_[60,70) Binary 0.0355 -0.0108 Balanced, &lt;0.1 ## age_[70,80) Binary 0.0144 0.0047 Balanced, &lt;0.1 ## age_[80, Inf) Binary -0.0643 0.0010 Balanced, &lt;0.1 ## sex_Female Binary -0.0462 -0.0143 Balanced, &lt;0.1 ## edu Contin. 0.0914 -0.0000 Balanced, &lt;0.1 ## DASIndex Contin. 0.0626 0.0435 Balanced, &lt;0.1 ## APACHE.score Contin. 0.5014 0.0109 Balanced, &lt;0.1 ## Glasgow.Coma.Score Contin. -0.1098 0.0034 Balanced, &lt;0.1 ## blood.pressure Contin. -0.4551 0.0057 Balanced, &lt;0.1 ## WBC Contin. 0.0836 0.0470 Balanced, &lt;0.1 ## Heart.rate Contin. 0.1469 0.0210 Balanced, &lt;0.1 ## Respiratory.rate Contin. -0.1655 0.0037 Balanced, &lt;0.1 ## Temperature Contin. -0.0214 0.0090 Balanced, &lt;0.1 ## PaO2vs.FIO2 Contin. -0.4332 -0.0016 Balanced, &lt;0.1 ## Albumin Contin. -0.2299 -0.0279 Balanced, &lt;0.1 ## Hematocrit Contin. -0.2693 -0.0247 Balanced, &lt;0.1 ## Bilirubin Contin. 0.1446 -0.0069 Balanced, &lt;0.1 ## Creatinine Contin. 0.2696 0.0148 Balanced, &lt;0.1 ## Sodium Contin. -0.0922 -0.0059 Balanced, &lt;0.1 ## Potassium Contin. -0.0271 -0.0264 Balanced, &lt;0.1 ## PaCo2 Contin. -0.2486 -0.0201 Balanced, &lt;0.1 ## PH Contin. -0.1198 0.0095 Balanced, &lt;0.1 ## Weight Contin. 0.2557 0.0209 Balanced, &lt;0.1 ## DNR.status_Yes Binary -0.0696 -0.0112 Balanced, &lt;0.1 ## Medical.insurance_Medicaid Binary -0.0395 0.0058 Balanced, &lt;0.1 ## Medical.insurance_Medicare Binary -0.0327 -0.0119 Balanced, &lt;0.1 ## Medical.insurance_Medicare &amp; Medicaid Binary -0.0144 -0.0001 Balanced, &lt;0.1 ## Medical.insurance_No insurance Binary 0.0099 -0.0002 Balanced, &lt;0.1 ## Medical.insurance_Private Binary 0.0624 0.0013 Balanced, &lt;0.1 ## Medical.insurance_Private &amp; Medicare Binary 0.0143 0.0052 Balanced, &lt;0.1 ## Respiratory.Diag_Yes Binary -0.1277 -0.0056 Balanced, &lt;0.1 ## Cardiovascular.Diag_Yes Binary 0.1395 0.0034 Balanced, &lt;0.1 ## Neurological.Diag_Yes Binary -0.1079 -0.0038 Balanced, &lt;0.1 ## Gastrointestinal.Diag_Yes Binary 0.0453 -0.0028 Balanced, &lt;0.1 ## Renal.Diag_Yes Binary 0.0264 0.0021 Balanced, &lt;0.1 ## Metabolic.Diag_Yes Binary -0.0059 0.0002 Balanced, &lt;0.1 ## Hematologic.Diag_Yes Binary -0.0146 -0.0000 Balanced, &lt;0.1 ## Sepsis.Diag_Yes Binary 0.0912 0.0035 Balanced, &lt;0.1 ## Trauma.Diag_Yes Binary 0.0105 0.0011 Balanced, &lt;0.1 ## Orthopedic.Diag_Yes Binary 0.0010 0.0002 Balanced, &lt;0.1 ## race_white Binary 0.0063 -0.0030 Balanced, &lt;0.1 ## race_black Binary -0.0114 0.0067 Balanced, &lt;0.1 ## race_other Binary 0.0050 -0.0036 Balanced, &lt;0.1 ## income_$11-$25k Binary 0.0062 -0.0096 Balanced, &lt;0.1 ## income_$25-$50k Binary 0.0391 0.0032 Balanced, &lt;0.1 ## income_&gt; $50k Binary 0.0165 -0.0001 Balanced, &lt;0.1 ## income_Under $11k Binary -0.0618 0.0065 Balanced, &lt;0.1 ## ## Balance tally for mean differences ## count ## Balanced, &lt;0.1 69 ## Not Balanced, &gt;0.1 0 ## ## Variable with the greatest mean difference ## Variable Diff.Adj M.Threshold ## WBC 0.047 Balanced, &lt;0.1 ## ## Effective sample sizes ## Control Treated ## Unadjusted 3551. 2184. ## Adjusted 2532.46 1039.44 We can also check this in a plot require(cobalt) love.plot(W.out, binary = &quot;std&quot;, thresholds = c(m = .1), abs = TRUE, var.order = &quot;unadjusted&quot;, line = TRUE) All covariates are balanced! Reverse engineered an RCT!?! 4.5 Step 4: outcome modelling Outcome modelling: \\(E(Y|A=1)\\) to obtain treatment effect estimate Estimate the effect of treatment on outcomes out.formula &lt;- as.formula(Y ~ A) out.fit &lt;- glm(out.formula, data = ObsData, weights = IPW) publish(out.fit) ## Variable Units Coefficient CI.95 p-value ## (Intercept) 20.68 [19.73;21.64] &lt; 1e-04 ## A 3.24 [1.88;4.60] &lt; 1e-04 saveRDS(out.fit, file = &quot;data/ipw.RDS&quot;) References "],["iptw-using-ml.html", "Chapter 5 IPTW using ML 5.1 IPTW Steps from SL 5.2 Step 1: exposure modelling 5.3 Step 2: Convert PS to IPW 5.4 Step 3: Balance checking 5.5 Step 4: outcome modelling", " Chapter 5 IPTW using ML Similar to G-computation, we will try to use machine learning methods, particularly Superlearner in estimating IPW estimates # Read the data saved at the last chapter ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) baselinevars &lt;- names(dplyr::select(ObsData, !c(A,Y))) ps.formula &lt;- as.formula(paste(&quot;A ~&quot;, paste(baselinevars, collapse = &quot;+&quot;))) 5.1 IPTW Steps from SL Modelling Steps: We will still follow the same steps Step 1 exposure modelling: \\(PS = Prob(A=1|L)\\) Step 2 Convert \\(PS\\) to \\(IPW\\) = \\(\\frac{A}{PS} + \\frac{1-A}{1-PS}\\) Step 3 Assess balance in weighted sample and overlap (\\(PS\\) and \\(L\\)) Step 4 outcome modelling: \\(Prob(Y=1|A=1)\\) to obtain treatment effect estimate 5.2 Step 1: exposure modelling This is the exposure model that we decided on: ps.formula ## A ~ Disease.category + Cancer + Cardiovascular + Congestive.HF + ## Dementia + Psychiatric + Pulmonary + Renal + Hepatic + GI.Bleed + ## Tumor + Immunosupperssion + Transfer.hx + MI + age + sex + ## edu + DASIndex + APACHE.score + Glasgow.Coma.Score + blood.pressure + ## WBC + Heart.rate + Respiratory.rate + Temperature + PaO2vs.FIO2 + ## Albumin + Hematocrit + Bilirubin + Creatinine + Sodium + ## Potassium + PaCo2 + PH + Weight + DNR.status + Medical.insurance + ## Respiratory.Diag + Cardiovascular.Diag + Neurological.Diag + ## Gastrointestinal.Diag + Renal.Diag + Metabolic.Diag + Hematologic.Diag + ## Sepsis.Diag + Trauma.Diag + Orthopedic.Diag + race + income Fit SuperLearner to estimate propensity scores. We again use the same candidate learners: linear model LASSO gradient boosting require(SuperLearner) ObsData.noYA &lt;- dplyr::select(ObsData, !c(Y,A)) PS.fit.SL &lt;- SuperLearner(Y=ObsData$A, X=ObsData.noYA, cvControl = list(V = 3), SL.library=c(&quot;SL.glm&quot;, &quot;SL.glmnet&quot;, &quot;SL.xgboost&quot;), method=&quot;method.NNLS&quot;, family=&quot;binomial&quot;) Here, method.AUC is also possible to use instead of method.NNLS for binary response. We could use cvControl = list(V = 3, stratifyCV = TRUE) to make the splits be stratified by the binary response. Obtain the propesnity score (PS) values from the fit all.pred &lt;- predict(PS.fit.SL, type = &quot;response&quot;) ObsData$PS.SL &lt;- all.pred$pred Check summaries: summary(ObsData$PS.SL) ## V1 ## Min. :0.002981 ## 1st Qu.:0.151578 ## Median :0.347286 ## Mean :0.380833 ## 3rd Qu.:0.591373 ## Max. :0.971231 tapply(ObsData$PS.SL, ObsData$A, summary) ## $`0` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.002981 0.091153 0.192876 0.224573 0.332211 0.788300 ## ## $`1` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0815 0.5107 0.6510 0.6349 0.7663 0.9712 plot(density(ObsData$PS.SL[ObsData$A==0]), col = &quot;red&quot;, main = &quot;&quot;) lines(density(ObsData$PS.SL[ObsData$A==1]), col = &quot;blue&quot;, lty = 2) legend(&quot;topright&quot;, c(&quot;No RHC&quot;,&quot;RHC&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty=1:2) 5.3 Step 2: Convert PS to IPW Convert PS from SL to IPW using the formula (again, ATE formula). ObsData$IPW.SL &lt;- ObsData$A/ObsData$PS.SL + (1-ObsData$A)/(1-ObsData$PS.SL) summary(ObsData$IPW.SL) ## V1 ## Min. : 1.003 ## 1st Qu.: 1.149 ## Median : 1.339 ## Mean : 1.508 ## 3rd Qu.: 1.668 ## Max. :12.271 Output from pre-packged software packages to do the same (very similar estimates): require(WeightIt) W.out &lt;- weightit(ps.formula, data = ObsData, estimand = &quot;ATE&quot;, method = &quot;super&quot;, SL.library = c(&quot;SL.glm&quot;, &quot;SL.glmnet&quot;, &quot;SL.xgboost&quot;)) summary(W.out$weights) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.002 1.141 1.321 1.471 1.626 12.435 saveRDS(W.out, file = &quot;data/ipwslps.RDS&quot;) Alternatively, you can use the previously estimated PS W.out2 &lt;- weightit(ps.formula, data = ObsData, estimand = &quot;ATE&quot;, ps = ObsData$PS.SL) summary(W.out2$weights) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.003 1.149 1.339 1.508 1.668 12.271 5.4 Step 3: Balance checking We first check balance numerically for SMD = 0.1 as threshold for balance. bal.tab(W.out, un = TRUE, thresholds = c(m = .1)) ## Call ## weightit(formula = ps.formula, data = ObsData, method = &quot;super&quot;, ## estimand = &quot;ATE&quot;, SL.library = c(&quot;SL.glm&quot;, &quot;SL.glmnet&quot;, &quot;SL.xgboost&quot;)) ## ## Balance Measures ## Type Diff.Un Diff.Adj ## prop.score Distance 2.7115 2.1229 ## Disease.category_ARF Binary -0.0290 -0.0094 ## Disease.category_CHF Binary 0.0261 0.0153 ## Disease.category_Other Binary -0.1737 -0.1013 ## Disease.category_MOSF Binary 0.1766 0.0954 ## Cancer_None Binary 0.0439 0.0249 ## Cancer_Localized (Yes) Binary -0.0267 -0.0120 ## Cancer_Metastatic Binary -0.0172 -0.0129 ## Cardiovascular Binary 0.0445 0.0283 ## Congestive.HF Binary 0.0268 0.0161 ## Dementia Binary -0.0472 -0.0296 ## Psychiatric Binary -0.0348 -0.0204 ## Pulmonary Binary -0.0737 -0.0430 ## Renal Binary 0.0066 0.0046 ## Hepatic Binary -0.0124 -0.0082 ## GI.Bleed Binary -0.0122 -0.0081 ## Tumor Binary -0.0423 -0.0230 ## Immunosupperssion Binary 0.0358 0.0200 ## Transfer.hx Binary 0.0554 0.0281 ## MI Binary 0.0139 0.0075 ## age_[-Inf,50) Binary -0.0017 -0.0014 ## age_[50,60) Binary 0.0161 0.0130 ## age_[60,70) Binary 0.0355 0.0167 ## age_[70,80) Binary 0.0144 0.0112 ## age_[80, Inf) Binary -0.0643 -0.0396 ## sex_Female Binary -0.0462 -0.0283 ## edu Contin. 0.0914 0.0512 ## DASIndex Contin. 0.0626 0.0378 ## APACHE.score Contin. 0.5014 0.2641 ## Glasgow.Coma.Score Contin. -0.1098 -0.0603 ## blood.pressure Contin. -0.4551 -0.2406 ## WBC Contin. 0.0836 0.0503 ## Heart.rate Contin. 0.1469 0.0819 ## Respiratory.rate Contin. -0.1655 -0.0829 ## Temperature Contin. -0.0214 -0.0060 ## PaO2vs.FIO2 Contin. -0.4332 -0.2339 ## Albumin Contin. -0.2299 -0.1292 ## Hematocrit Contin. -0.2693 -0.1590 ## Bilirubin Contin. 0.1446 0.0771 ## Creatinine Contin. 0.2696 0.1425 ## Sodium Contin. -0.0922 -0.0513 ## Potassium Contin. -0.0271 -0.0284 ## PaCo2 Contin. -0.2486 -0.1483 ## PH Contin. -0.1198 -0.0533 ## Weight Contin. 0.2557 0.1418 ## DNR.status_Yes Binary -0.0696 -0.0426 ## Medical.insurance_Medicaid Binary -0.0395 -0.0224 ## Medical.insurance_Medicare Binary -0.0327 -0.0184 ## Medical.insurance_Medicare &amp; Medicaid Binary -0.0144 -0.0065 ## Medical.insurance_No insurance Binary 0.0099 0.0062 ## Medical.insurance_Private Binary 0.0624 0.0333 ## Medical.insurance_Private &amp; Medicare Binary 0.0143 0.0077 ## Respiratory.Diag_Yes Binary -0.1277 -0.0673 ## Cardiovascular.Diag_Yes Binary 0.1395 0.0760 ## Neurological.Diag_Yes Binary -0.1079 -0.0592 ## Gastrointestinal.Diag_Yes Binary 0.0453 0.0249 ## Renal.Diag_Yes Binary 0.0264 0.0148 ## Metabolic.Diag_Yes Binary -0.0059 -0.0027 ## Hematologic.Diag_Yes Binary -0.0146 -0.0084 ## Sepsis.Diag_Yes Binary 0.0912 0.0485 ## Trauma.Diag_Yes Binary 0.0105 0.0064 ## Orthopedic.Diag_Yes Binary 0.0010 0.0007 ## race_white Binary 0.0063 0.0034 ## race_black Binary -0.0114 -0.0043 ## race_other Binary 0.0050 0.0009 ## income_$11-$25k Binary 0.0062 0.0007 ## income_$25-$50k Binary 0.0391 0.0211 ## income_&gt; $50k Binary 0.0165 0.0078 ## income_Under $11k Binary -0.0618 -0.0296 ## M.Threshold ## prop.score ## Disease.category_ARF Balanced, &lt;0.1 ## Disease.category_CHF Balanced, &lt;0.1 ## Disease.category_Other Not Balanced, &gt;0.1 ## Disease.category_MOSF Balanced, &lt;0.1 ## Cancer_None Balanced, &lt;0.1 ## Cancer_Localized (Yes) Balanced, &lt;0.1 ## Cancer_Metastatic Balanced, &lt;0.1 ## Cardiovascular Balanced, &lt;0.1 ## Congestive.HF Balanced, &lt;0.1 ## Dementia Balanced, &lt;0.1 ## Psychiatric Balanced, &lt;0.1 ## Pulmonary Balanced, &lt;0.1 ## Renal Balanced, &lt;0.1 ## Hepatic Balanced, &lt;0.1 ## GI.Bleed Balanced, &lt;0.1 ## Tumor Balanced, &lt;0.1 ## Immunosupperssion Balanced, &lt;0.1 ## Transfer.hx Balanced, &lt;0.1 ## MI Balanced, &lt;0.1 ## age_[-Inf,50) Balanced, &lt;0.1 ## age_[50,60) Balanced, &lt;0.1 ## age_[60,70) Balanced, &lt;0.1 ## age_[70,80) Balanced, &lt;0.1 ## age_[80, Inf) Balanced, &lt;0.1 ## sex_Female Balanced, &lt;0.1 ## edu Balanced, &lt;0.1 ## DASIndex Balanced, &lt;0.1 ## APACHE.score Not Balanced, &gt;0.1 ## Glasgow.Coma.Score Balanced, &lt;0.1 ## blood.pressure Not Balanced, &gt;0.1 ## WBC Balanced, &lt;0.1 ## Heart.rate Balanced, &lt;0.1 ## Respiratory.rate Balanced, &lt;0.1 ## Temperature Balanced, &lt;0.1 ## PaO2vs.FIO2 Not Balanced, &gt;0.1 ## Albumin Not Balanced, &gt;0.1 ## Hematocrit Not Balanced, &gt;0.1 ## Bilirubin Balanced, &lt;0.1 ## Creatinine Not Balanced, &gt;0.1 ## Sodium Balanced, &lt;0.1 ## Potassium Balanced, &lt;0.1 ## PaCo2 Not Balanced, &gt;0.1 ## PH Balanced, &lt;0.1 ## Weight Not Balanced, &gt;0.1 ## DNR.status_Yes Balanced, &lt;0.1 ## Medical.insurance_Medicaid Balanced, &lt;0.1 ## Medical.insurance_Medicare Balanced, &lt;0.1 ## Medical.insurance_Medicare &amp; Medicaid Balanced, &lt;0.1 ## Medical.insurance_No insurance Balanced, &lt;0.1 ## Medical.insurance_Private Balanced, &lt;0.1 ## Medical.insurance_Private &amp; Medicare Balanced, &lt;0.1 ## Respiratory.Diag_Yes Balanced, &lt;0.1 ## Cardiovascular.Diag_Yes Balanced, &lt;0.1 ## Neurological.Diag_Yes Balanced, &lt;0.1 ## Gastrointestinal.Diag_Yes Balanced, &lt;0.1 ## Renal.Diag_Yes Balanced, &lt;0.1 ## Metabolic.Diag_Yes Balanced, &lt;0.1 ## Hematologic.Diag_Yes Balanced, &lt;0.1 ## Sepsis.Diag_Yes Balanced, &lt;0.1 ## Trauma.Diag_Yes Balanced, &lt;0.1 ## Orthopedic.Diag_Yes Balanced, &lt;0.1 ## race_white Balanced, &lt;0.1 ## race_black Balanced, &lt;0.1 ## race_other Balanced, &lt;0.1 ## income_$11-$25k Balanced, &lt;0.1 ## income_$25-$50k Balanced, &lt;0.1 ## income_&gt; $50k Balanced, &lt;0.1 ## income_Under $11k Balanced, &lt;0.1 ## ## Balance tally for mean differences ## count ## Balanced, &lt;0.1 59 ## Not Balanced, &gt;0.1 9 ## ## Variable with the greatest mean difference ## Variable Diff.Adj M.Threshold ## APACHE.score 0.2641 Not Balanced, &gt;0.1 ## ## Effective sample sizes ## Control Treated ## Unadjusted 3551. 2184. ## Adjusted 3316.37 1896.5 And also via plot require(cobalt) love.plot(W.out, binary = &quot;std&quot;, thresholds = c(m = .1), abs = TRUE, var.order = &quot;unadjusted&quot;, line = TRUE) Some covariates have SMD &gt; 0.1 (sign of imbalance). This phenomenon is common when we use strong ML methods to obtain PS (Alam, Moodie, and Stephens 2019). 5.5 Step 4: outcome modelling Estimate the effect of treatment on outcomes 5.5.1 Crude out.formula &lt;- as.formula(Y ~ A) out.fit &lt;- glm(out.formula, data = ObsData, weights = IPW.SL) publish(out.fit) ## Variable Units Coefficient CI.95 p-value ## (Intercept) 20.21 [19.31;21.12] &lt; 1e-04 ## A 4.24 [2.88;5.61] &lt; 1e-04 5.5.2 Adjusted Adjusting for all covariates to deal with potential residual confounding (as was indicated by imbalance). Alternatively, could adjust for selected covariates believed to be the reasons for potential imbalance (Nguyen et al. 2017). Estimate the effect of treatment on outcomes (after adjustment) out.formula2 &lt;- as.formula(paste(&quot;Y~ A +&quot;, paste(baselinevars, collapse = &quot;+&quot;))) out.fit2 &lt;- glm(out.formula2, data = ObsData, weights = IPW.SL) res2 &lt;- publish(out.fit2, digits=1)$regressionTable[2,] res2 Table 5.1: VariableUnitsCoefficientCI.95p-value A2.9[1.5;4.3]&lt;0.1 5.5.3 Adjusted (from package) Also check the output when we used the weights from the package out.fit3 &lt;- glm(out.formula2, data = ObsData, weights = W.out$weights) res3 &lt;- publish(out.fit3, digits=1)$regressionTable[2,] res3 Table 5.2: VariableUnitsCoefficientCI.95p-value A2.9[1.5;4.3]&lt;0.1 saveRDS(out.fit3, file = &quot;data/ipwsl.RDS&quot;) References "],["tmle.html", "Chapter 6 TMLE 6.1 Doubly robust estimators 6.2 TMLE 6.3 TMLE Steps 6.4 Step 1: Transformation of Y 6.5 Step 2: Initial G-comp estimate 6.6 Step 3: PS model 6.7 Step 4: Estimate \\(H\\) 6.8 Step 5: Estimate \\(\\epsilon\\) 6.9 Step 6: Update 6.10 Step 7: Effect estimate 6.11 Step 8: Rescale effect estimate 6.12 Step 9: Confidence interval estimation", " Chapter 6 TMLE 6.1 Doubly robust estimators Now that we have covered outcome models (e.g., G-computation) and exposure models (e.g., propensity score models), let us talk about doubly robust (DR) estimators. DR has several important properties: They use information from both the exposure and the outcome models. They provide a consistent estimator if either of the above mentioned models is correctly specified. consistent estimator means as the sample size increases, distribution of the estimates gets concentrated near the true parameter They provide an efficient estimator if both the exposure and the outcome model are correctly specified. efficient estimator means estimates approximates the true parameter in terms of a chosen loss function (e.g., could be RMSE). 6.2 TMLE Targeted Maximum Likelihood Estimation (TMLE) is a DR method, using an initial estimate from the outcome model (G-computation) the propensity score (exposure) model to improve. In addition to being DR, TMLE has several other desirable properties: It allows the use of data-adaptive algorithms like machine learning without sacrificing interpretability. ML is only used in intermediary steps to develop the estimator, so the optimization and interpretation of the estimator as a whole remains intact. The use of machine learning can help mitigate model misspecification. It has been shown to outperform other methods, particularly in sparse data settings. 6.3 TMLE Steps According to Luque-Fernandez et al. (2018), we need to the following steps (2-7) for obtaining point estimates when dealing with binary outcome. But as we are dealing with continuous outcome, we need an added transformation step at the beginning, and also at the end. Step 1 Transformation of continuous outcome variable Step 2 Predict from initial outcome modelling: G-computation Step 3 Predict from propensity score model Step 4 Estimate clever covariate \\(H\\) Step 5 Estimate fluctuation parameter \\(\\epsilon\\) Step 6 Update the initial outcome model prediction based on targeted adjustment of the initial predictions using the PS model Step 7 Find treatment effect estimate Step 8 Transform back the treatment effect estimate in the original outcome scale Step 9 Confidence interval estimation based on closed form formula We will go through the steps of TMLE one-by-one, using the RHC dataset presented in previous chapters. As a reminder, the exposure we are considering is RHC (right heart catheterization) and the outcome of interest is length of stay in the hospital. # Read the data saved at the last chapter ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) 6.4 Step 1: Transformation of Y In our example, the outcome is continuous. summary(ObsData$Y) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.00 7.00 14.00 21.56 25.00 394.00 plot(density(ObsData$Y), main = &quot;Observed Y&quot;) General recommendation is to transform continuous outcome to be within the range [0,1] (Susan Gruber and Laan 2010). min.Y &lt;- min(ObsData$Y) max.Y &lt;- max(ObsData$Y) ObsData$Y.bounded &lt;- (ObsData$Y-min.Y)/(max.Y-min.Y) Check the range of our transformed outcome variable summary(ObsData$Y.bounded) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00000 0.01276 0.03061 0.04990 0.05867 1.00000 6.5 Step 2: Initial G-comp estimate We construct our outcome model, and make our initial predictions. For this step, we will use SuperLearner. This requires no apriori assumptions about the structure of our outcome model. library(SuperLearner) set.seed(123) ObsData.noY &lt;- dplyr::select(ObsData, !c(Y,Y.bounded)) Y.fit.sl &lt;- SuperLearner(Y=ObsData$Y.bounded, X=ObsData.noY, cvControl = list(V = 3), SL.library=c(&quot;SL.glm&quot;, &quot;SL.glmnet&quot;, &quot;SL.xgboost&quot;), method=&quot;method.CC_nloglik&quot;, family=&quot;gaussian&quot;) ObsData$init.Pred &lt;- predict(Y.fit.sl, newdata = ObsData.noY, type = &quot;response&quot;)$pred summary(ObsData$init.Pred) ## V1 ## Min. :0.00100 ## 1st Qu.:0.03723 ## Median :0.04948 ## Mean :0.04877 ## 3rd Qu.:0.06067 ## Max. :0.13659 # alternatively, we could write # ObsData$init.Pred &lt;- Y.fit.sl$SL.predict We will use these initial prediction values later. \\(Q^0(A,L)\\) is often used to represent the predictions from initial G-comp model. 6.5.1 Get predictions under both treatments \\(A = 0\\) and \\(1\\) We could estimate the treatment effect from this initial model. We will need the \\(Q^0(A=1,L)\\) and \\(Q^0(A=0,L)\\) predictions later. \\(Q^0(A=1,L)\\) predictions: ObsData.noY$A &lt;- 1 ObsData$Pred.Y1 &lt;- predict(Y.fit.sl, newdata = ObsData.noY, type = &quot;response&quot;)$pred summary(ObsData$Pred.Y1) ## V1 ## Min. :0.00100 ## 1st Qu.:0.04240 ## Median :0.05429 ## Mean :0.05322 ## 3rd Qu.:0.06446 ## Max. :0.13659 \\(Q^0(A=0,L)\\) predictions: ObsData.noY$A &lt;- 0 ObsData$Pred.Y0 &lt;- predict(Y.fit.sl, newdata = ObsData.noY, type = &quot;response&quot;)$pred summary(ObsData$Pred.Y0) ## V1 ## Min. :0.00100 ## 1st Qu.:0.03524 ## Median :0.04708 ## Mean :0.04609 ## 3rd Qu.:0.05734 ## Max. :0.12652 6.5.2 Get initial treatment effect estimate ObsData$Pred.TE &lt;- ObsData$Pred.Y1 - ObsData$Pred.Y0 summary(ObsData$Pred.TE) ## V1 ## Min. :-0.010333 ## 1st Qu.: 0.006682 ## Median : 0.007071 ## Mean : 0.007134 ## 3rd Qu.: 0.007541 ## Max. : 0.021592 6.6 Step 3: PS model At this point, we have our initial estimate and now want to perform our targeted improvement. library(SuperLearner) set.seed(124) ObsData.noYA &lt;- dplyr::select(ObsData, !c(Y,Y.bounded, A,init.Pred, Pred.Y1,Pred.Y0, Pred.TE)) PS.fit.SL &lt;- SuperLearner(Y=ObsData$A, X=ObsData.noYA, cvControl = list(V = 3), SL.library=c(&quot;SL.glm&quot;, &quot;SL.glmnet&quot;, &quot;SL.xgboost&quot;), method=&quot;method.CC_nloglik&quot;, family=&quot;binomial&quot;) all.pred &lt;- predict(PS.fit.SL, type = &quot;response&quot;) ObsData$PS.SL &lt;- all.pred$pred These propensity score predictions (PS.SL) are represented as \\(g(A_i=1|L_i)\\). We can estimate \\(g(A_i=0|L_i)\\) as \\(1 - g(A_i=1|L_i)\\) or 1 - PS.SL. summary(ObsData$PS.SL) ## V1 ## Min. :0.002806 ## 1st Qu.:0.133409 ## Median :0.329181 ## Mean :0.375143 ## 3rd Qu.:0.596584 ## Max. :0.983057 tapply(ObsData$PS.SL, ObsData$A, summary) ## $`0` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.002806 0.079637 0.177020 0.219962 0.327519 0.866585 ## ## $`1` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.03745 0.49045 0.65384 0.62745 0.78263 0.98306 plot(density(ObsData$PS.SL[ObsData$A==0]), col = &quot;red&quot;, main = &quot;&quot;) lines(density(ObsData$PS.SL[ObsData$A==1]), col = &quot;blue&quot;, lty = 2) legend(&quot;topright&quot;, c(&quot;No RHC&quot;,&quot;RHC&quot;), col = c(&quot;red&quot;, &quot;blue&quot;), lty=1:2) 6.7 Step 4: Estimate \\(H\\) Clever covariate \\(H(A_i, L_i) = \\frac{I(A_i=1)}{g(A_i=1|L_i)} - \\frac{I(A_i=0)}{g(A_i=0|L_i)}\\) (Luque-Fernandez et al. 2018) ObsData$H.A1L &lt;- (ObsData$A) / ObsData$PS.SL ObsData$H.A0L &lt;- (1-ObsData$A) / (1- ObsData$PS.SL) ObsData$H.AL &lt;- ObsData$H.A1L - ObsData$H.A0L summary(ObsData$H.AL) ## V1 ## Min. :-7.4954 ## 1st Qu.:-1.2922 ## Median :-1.0659 ## Mean :-0.1378 ## 3rd Qu.: 1.3662 ## Max. :26.7017 tapply(ObsData$H.AL, ObsData$A, summary) ## $`0` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -7.495 -1.487 -1.215 -1.377 -1.087 -1.003 ## ## $`1` ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.017 1.278 1.529 1.878 2.039 26.702 t(apply(cbind(-ObsData$H.A0L,ObsData$H.A1L), 2, summary)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## [1,] -7.495399 -1.292187 -1.065943 -0.8527551 0.000000 0.0000 ## [2,] 0.000000 0.000000 0.000000 0.7150032 1.366217 26.7017 Aggregated or individual clever covariate components show slight difference in their summaries. 6.8 Step 5: Estimate \\(\\epsilon\\) Fluctuation parameter \\(\\epsilon\\), representing how large of an adjustment we will make to the initial estimate. The fluctuation parameter \\(\\hat\\epsilon\\) could be a scalar or a vector with 2 components \\(\\hat\\epsilon_0\\) and \\(\\hat\\epsilon_1\\). It is estimated through MLE, using a model with an offset based on the initial estimate, and clever covariates as independent variables (Susan Gruber and Van Der Laan 2009): \\(E(Y|A,L)(\\epsilon) = \\frac{1}{1+\\exp(-\\log\\frac{\\bar Q^0(A,L)}{(1-\\bar Q^0(A,L))}-\\epsilon \\times H(A,L))}\\) 6.8.1 \\(\\hat\\epsilon\\) = \\(\\hat\\epsilon_0\\) and \\(\\hat\\epsilon_1\\) This is closer to how tmle package has implement clever covariates eps_mod &lt;- glm(Y.bounded ~ -1 + H.A1L + H.A0L + offset(qlogis(init.Pred)), family = &quot;binomial&quot;, data = ObsData) epsilon &lt;- coef(eps_mod) epsilon[&quot;H.A1L&quot;] ## H.A1L ## 0.01568809 epsilon[&quot;H.A0L&quot;] ## H.A0L ## 0.02070037 Note that, if init.Pred includes negative values, NaNs would be produced after applying qlogis(). 6.8.2 Only 1 \\(\\hat\\epsilon\\) For demonstration purposes eps_mod1 &lt;- glm(Y.bounded ~ -1 + H.AL + offset(qlogis(init.Pred)), family = &quot;binomial&quot;, data = ObsData) epsilon1 &lt;- coef(eps_mod1) epsilon1 ## H.AL ## 0.001845536 Alternative could be to use H.AL as weights (not shown here). 6.9 Step 6: Update 6.9.1 \\(\\hat\\epsilon\\) = \\(\\hat\\epsilon_0\\) and \\(\\hat\\epsilon_1\\) We can use epsilon[\"H.A1L\"] and epsilon[\"H.A0L\"] to update ObsData$Pred.Y1.update &lt;- plogis(qlogis(ObsData$Pred.Y1) + epsilon[&quot;H.A1L&quot;]*ObsData$H.A1L) ObsData$Pred.Y0.update &lt;- plogis(qlogis(ObsData$Pred.Y0) + epsilon[&quot;H.A0L&quot;]*ObsData$H.A0L) summary(ObsData$Pred.Y1.update) ## V1 ## Min. :0.001031 ## 1st Qu.:0.042745 ## Median :0.054882 ## Mean :0.053810 ## 3rd Qu.:0.065188 ## Max. :0.139189 summary(ObsData$Pred.Y0.update) ## V1 ## Min. :0.00100 ## 1st Qu.:0.03603 ## Median :0.04779 ## Mean :0.04686 ## 3rd Qu.:0.05809 ## Max. :0.12652 6.9.2 Only 1 \\(\\hat\\epsilon\\) Alternatively, we could use epsilon to from H.AL to update ObsData$Pred.Y1.update1 &lt;- plogis(qlogis(ObsData$Pred.Y1) + epsilon1*ObsData$H.AL) ObsData$Pred.Y0.update1 &lt;- plogis(qlogis(ObsData$Pred.Y0) + epsilon1*ObsData$H.AL) summary(ObsData$Pred.Y1.update1) ## V1 ## Min. :0.001004 ## 1st Qu.:0.042323 ## Median :0.054282 ## Mean :0.053210 ## 3rd Qu.:0.064424 ## Max. :0.136895 summary(ObsData$Pred.Y0.update1) ## V1 ## Min. :0.001004 ## 1st Qu.:0.035254 ## Median :0.047066 ## Mean :0.046077 ## 3rd Qu.:0.057296 ## Max. :0.126804 Note that, if Pred.Y1 and Pred.Y0 include negative values, NaNs would be produced after applying qlogis(). 6.10 Step 7: Effect estimate Now that the updated predictions of our outcome models are calculated, we can calculate the ATE. 6.10.1 \\(\\hat\\epsilon\\) = \\(\\hat\\epsilon_0\\) and \\(\\hat\\epsilon_1\\) ATE.TMLE.bounded.vector &lt;- ObsData$Pred.Y1.update - ObsData$Pred.Y0.update summary(ATE.TMLE.bounded.vector) ## V1 ## Min. :-0.011371 ## 1st Qu.: 0.005740 ## Median : 0.006569 ## Mean : 0.006954 ## 3rd Qu.: 0.008228 ## Max. : 0.031895 ATE.TMLE.bounded &lt;- mean(ATE.TMLE.bounded.vector, na.rm = TRUE) ATE.TMLE.bounded ## [1] 0.006953925 6.10.2 Only 1 \\(\\hat\\epsilon\\) Alternatively, using H.AL: ATE.TMLE.bounded.vector1 &lt;- ObsData$Pred.Y1.update1 - ObsData$Pred.Y0.update1 summary(ATE.TMLE.bounded.vector1) ## V1 ## Min. :-0.010315 ## 1st Qu.: 0.006681 ## Median : 0.007066 ## Mean : 0.007133 ## 3rd Qu.: 0.007540 ## Max. : 0.021637 ATE.TMLE.bounded1 &lt;- mean(ATE.TMLE.bounded.vector1, na.rm = TRUE) ATE.TMLE.bounded1 ## [1] 0.007132696 6.11 Step 8: Rescale effect estimate We make sure to transform back to our original scale. 6.11.1 \\(\\hat\\epsilon\\) = \\(\\hat\\epsilon_0\\) and \\(\\hat\\epsilon_1\\) ATE.TMLE &lt;- (max.Y-min.Y)*ATE.TMLE.bounded ATE.TMLE ## [1] 2.725938 6.11.2 Only 1 \\(\\hat\\epsilon\\) Alternatively, using H.AL: ATE.TMLE1 &lt;- (max.Y-min.Y)*ATE.TMLE.bounded1 ATE.TMLE1 ## [1] 2.796017 6.12 Step 9: Confidence interval estimation Since the machine learning algorithms were used only in intermediary steps, rather than estimating our parameter of interest directly, 95% confidence intervals can be calculated directly (Luque-Fernandez et al. 2018). Based on semi-parametric theory, closed form variance formula is already derived (Laan and Petersen 2012). Time-consuming bootstrap procedure is not necessary. ci.estimate &lt;- function(data = ObsData, H.AL.components = 1){ min.Y &lt;- min(data$Y) max.Y &lt;- max(data$Y) # transform predicted outcomes back to original scale if (H.AL.components == 2){ data$Pred.Y1.update.rescaled &lt;- (max.Y- min.Y)*data$Pred.Y1.update + min.Y data$Pred.Y0.update.rescaled &lt;- (max.Y- min.Y)*data$Pred.Y0.update + min.Y } if (H.AL.components == 1) { data$Pred.Y1.update.rescaled &lt;- (max.Y- min.Y)*data$Pred.Y1.update1 + min.Y data$Pred.Y0.update.rescaled &lt;- (max.Y- min.Y)*data$Pred.Y0.update1 + min.Y } EY1_TMLE1 &lt;- mean(data$Pred.Y1.update.rescaled, na.rm = TRUE) EY0_TMLE1 &lt;- mean(data$Pred.Y0.update.rescaled, na.rm = TRUE) # ATE efficient influence curve D1 &lt;- data$A/data$PS.SL* (data$Y - data$Pred.Y1.update.rescaled) + data$Pred.Y1.update.rescaled - EY1_TMLE1 D0 &lt;- (1 - data$A)/(1 - data$PS.SL)* (data$Y - data$Pred.Y0.update.rescaled) + data$Pred.Y0.update.rescaled - EY0_TMLE1 EIC &lt;- D1 - D0 # ATE variance n &lt;- nrow(data) varHat.IC &lt;- var(EIC, na.rm = TRUE)/n # ATE 95% CI if (H.AL.components == 2) { ATE.TMLE.CI &lt;- c(ATE.TMLE - 1.96*sqrt(varHat.IC), ATE.TMLE + 1.96*sqrt(varHat.IC)) } if (H.AL.components == 1) { ATE.TMLE.CI &lt;- c(ATE.TMLE1 - 1.96*sqrt(varHat.IC), ATE.TMLE1 + 1.96*sqrt(varHat.IC)) } return(ATE.TMLE.CI) } 6.12.1 \\(\\hat\\epsilon\\) = \\(\\hat\\epsilon_0\\) and \\(\\hat\\epsilon_1\\) CI2 &lt;- ci.estimate(data = ObsData, H.AL.components = 2) CI2 ## [1] 1.585188 3.866689 6.12.2 Only 1 \\(\\hat\\epsilon\\) CI1 &lt;- ci.estimate(data = ObsData, H.AL.components = 1) CI1 ## [1] 1.654637 3.937396 saveRDS(ATE.TMLE, file = &quot;data/tmlepointh.RDS&quot;) saveRDS(CI2, file = &quot;data/tmlecih.RDS&quot;) # Read the data saved at the last chapter ObsData &lt;- readRDS(file = &quot;data/rhcAnalytic.RDS&quot;) dim(ObsData) ## [1] 5735 51 References "],["pre-packaged-software.html", "Chapter 7 Pre-packaged software 7.1 tmle 7.2 tmle (reduced computation) 7.3 sl3 (optional) 7.4 RHC results 7.5 Other packages", " Chapter 7 Pre-packaged software 7.1 tmle The tmle package can handle both binary and continuous outcomes, and uses the SuperLearner package to construct both models just like we did in the steps above. The default SuperLearner library for estimating the outcome includes (S. Gruber, Van Der Laan, and Kennedy 2020) SL.glm: generalized linear models (GLMs) SL.glmnet: LASSO tmle.SL.dbarts2: modeling and prediction using BART The default library for estimating the propensity scores includes SL.glm: generalized linear models (GLMs) tmle.SL.dbarts.k.5: SL wrappers for modeling and prediction using BART SL.gam: generalized additive models: (GAMs) It is certainly possible to use different set of learners More methods can be added by specifying lists of models in the Q.SL.library (for the outcome model) and g.SL.library (for the propensity score model) arguments. Note also that the outcome \\(Y\\) is required to be within the range of \\([0,1]\\) for this method as well, so we need to pass in the transformed data, then transform back the estimate. set.seed(1444) # transform the outcome to fall within the range [0,1] min.Y &lt;- min(ObsData$Y) max.Y &lt;- max(ObsData$Y) ObsData$Y_transf &lt;- (ObsData$Y-min.Y)/(max.Y-min.Y) # run tmle from the tmle package ObsData.noYA &lt;- dplyr::select(ObsData, !c(Y_transf, Y, A)) SL.library = c(&quot;SL.glm&quot;, &quot;SL.glmnet&quot;, &quot;SL.xgboost&quot;) tmle.fit &lt;- tmle::tmle(Y = ObsData$Y_transf, A = ObsData$A, W = ObsData.noYA, family = &quot;gaussian&quot;, V = 3, Q.SL.library = SL.library, g.SL.library = SL.library) tmle.fit ## Additive Effect ## Parameter Estimate: 0.0073229 ## Estimated Variance: 2.0642e-06 ## p-value: 3.4526e-07 ## 95% Conf Interval: (0.0045069, 0.010139) ## ## Additive Effect among the Treated ## Parameter Estimate: 0.0054449 ## Estimated Variance: 3.4095e-06 ## p-value: 0.00319 ## 95% Conf Interval: (0.0018258, 0.0090641) ## ## Additive Effect among the Controls ## Parameter Estimate: 0.01266 ## Estimated Variance: 1.9251e-06 ## p-value: &lt;2e-16 ## 95% Conf Interval: (0.0099407, 0.01538) summary(tmle.fit) ## Initial estimation of Q ## Procedure: cv-SuperLearner, ensemble ## Model: ## Y ~ SL.glm_All + SL.glmnet_All + SL.xgboost_All ## ## Coefficients: ## SL.glm_All 0.316376 ## SL.glmnet_All 0.4996009 ## SL.xgboost_All 0.1840231 ## ## Cross-validated R squared : 0.0607 ## ## Estimation of g (treatment mechanism) ## Procedure: SuperLearner, ensemble Empirical AUC = 0.9388 ## ## Model: ## A ~ SL.glm_All + SL.glmnet_All + SL.xgboost_All ## ## Coefficients: ## SL.glm_All 0 ## SL.glmnet_All 0.6490267 ## SL.xgboost_All 0.3509733 ## ## Estimation of g.Z (intermediate variable assignment mechanism) ## Procedure: No intermediate variable ## ## Estimation of g.Delta (missingness mechanism) ## Procedure: No missingness, ensemble ## ## Bounds on g: (0.0076, 1) ## ## Bounds on g for ATT/ATE: (0.0076, 0.9924) ## ## Additive Effect ## Parameter Estimate: 0.0073229 ## Estimated Variance: 2.0642e-06 ## p-value: 3.4526e-07 ## 95% Conf Interval: (0.0045069, 0.010139) ## ## Additive Effect among the Treated ## Parameter Estimate: 0.0054449 ## Estimated Variance: 3.4095e-06 ## p-value: 0.00319 ## 95% Conf Interval: (0.0018258, 0.0090641) ## ## Additive Effect among the Controls ## Parameter Estimate: 0.01266 ## Estimated Variance: 1.9251e-06 ## p-value: &lt;2e-16 ## 95% Conf Interval: (0.0099407, 0.01538) tmle_est_tr &lt;- tmle.fit$estimates$ATE$psi tmle_est_tr ## [1] 0.00732285 # transform back the ATE estimate tmle_est &lt;- (max.Y-min.Y)*tmle_est_tr tmle_est ## [1] 2.870557 saveRDS(tmle_est, file = &quot;data/tmle.RDS&quot;) tmle_ci &lt;- paste(&quot;(&quot;, round((max.Y-min.Y)*tmle.fit$estimates$ATE$CI[1], 3), &quot;, &quot;, round((max.Y-min.Y)*tmle.fit$estimates$ATE$CI[2], 3), &quot;)&quot;, sep = &quot;&quot;) tmle.ci &lt;- (max.Y-min.Y)*tmle.fit$estimates$ATE$CI saveRDS(tmle.ci, file = &quot;data/tmleci.RDS&quot;) ## ATE from tmle package: 2.870557(1.767, 3.974) Notes about the tmle package: does not scale the outcome for you can give some error messages when dealing with variable types it is not expecting practically all steps are nicely packed up in one function, very easy to use but need to dig a little to truly understand what it does Most helpful resources: CRAN docs tmle package paper 7.2 tmle (reduced computation) We can use the previously calculated propensity score predictions from SL (calculated using WeightIt package) in the tmle to reduce some computing time. ps.obj &lt;- readRDS(file = &quot;data/ipwslps.RDS&quot;) ps.SL &lt;- ps.obj$weights tmle.fit2 &lt;- tmle::tmle(Y = ObsData$Y_transf, A = ObsData$A, W = ObsData.noYA, family = &quot;gaussian&quot;, V = 3, Q.SL.library = SL.library, g1W = ps.SL) tmle.fit2 ## Additive Effect ## Parameter Estimate: 0.0079113 ## Estimated Variance: 0.0063697 ## p-value: 0.92104 ## 95% Conf Interval: (-0.14852, 0.16434) ## ## Additive Effect among the Treated ## Parameter Estimate: 0.016964 ## Estimated Variance: 0.043265 ## p-value: 0.935 ## 95% Conf Interval: (-0.39072, 0.42465) ## ## Additive Effect among the Controls ## Warning: Procedure failed to converge ## Parameter Estimate: 0.00063631 ## Estimated Variance: 9.7303e-07 ## p-value: 0.51888 ## 95% Conf Interval: (-0.0012971, 0.0025697) # transform back ATE estimate (max.Y-min.Y)*tmle.fit2$estimates$ATE$psi ## [1] 3.101232 7.3 sl3 (optional) # install sl3 if not done so # remotes::install_github(&quot;tlverse/sl3&quot;) The sl3 package is a newer package, that implements two types of Super Learning: discrete Super Learning, in which the best prediction algorithm (based on cross-validation) from a specified library is returned, and ensemble Super Learning, in which the best linear combination of the specified algorithms is returned (Coyle, Hejazi, Malenica, et al. (2021)). The first step is to create a sl3 task which keeps track of the roles of the variables in our problem (Coyle, Hejazi, Melencia, et al. (2021)). require(sl3) # create sl3 task, specifying outcome and covariates rhc_task &lt;- make_sl3_Task( data = ObsData, covariates = colnames(ObsData)[-which(names(ObsData) == &quot;Y&quot;)], outcome = &quot;Y&quot; ) rhc_task ## A sl3 Task with 5735 obs and these nodes: ## $covariates ## [1] &quot;Disease.category&quot; &quot;Cancer&quot; &quot;Cardiovascular&quot; ## [4] &quot;Congestive.HF&quot; &quot;Dementia&quot; &quot;Psychiatric&quot; ## [7] &quot;Pulmonary&quot; &quot;Renal&quot; &quot;Hepatic&quot; ## [10] &quot;GI.Bleed&quot; &quot;Tumor&quot; &quot;Immunosupperssion&quot; ## [13] &quot;Transfer.hx&quot; &quot;MI&quot; &quot;age&quot; ## [16] &quot;sex&quot; &quot;edu&quot; &quot;DASIndex&quot; ## [19] &quot;APACHE.score&quot; &quot;Glasgow.Coma.Score&quot; &quot;blood.pressure&quot; ## [22] &quot;WBC&quot; &quot;Heart.rate&quot; &quot;Respiratory.rate&quot; ## [25] &quot;Temperature&quot; &quot;PaO2vs.FIO2&quot; &quot;Albumin&quot; ## [28] &quot;Hematocrit&quot; &quot;Bilirubin&quot; &quot;Creatinine&quot; ## [31] &quot;Sodium&quot; &quot;Potassium&quot; &quot;PaCo2&quot; ## [34] &quot;PH&quot; &quot;Weight&quot; &quot;DNR.status&quot; ## [37] &quot;Medical.insurance&quot; &quot;Respiratory.Diag&quot; &quot;Cardiovascular.Diag&quot; ## [40] &quot;Neurological.Diag&quot; &quot;Gastrointestinal.Diag&quot; &quot;Renal.Diag&quot; ## [43] &quot;Metabolic.Diag&quot; &quot;Hematologic.Diag&quot; &quot;Sepsis.Diag&quot; ## [46] &quot;Trauma.Diag&quot; &quot;Orthopedic.Diag&quot; &quot;race&quot; ## [49] &quot;income&quot; &quot;A&quot; &quot;Y_transf&quot; ## ## $outcome ## [1] &quot;Y&quot; ## ## $id ## NULL ## ## $weights ## NULL ## ## $offset ## NULL ## ## $time ## NULL Next, we create our SuperLearner. To do this, we need to specify a selection of machine learning algorithms we want to include as candidates, as well as a metalearner that the SuperLearner will use to combine or choose from the machine learning algorithms provided (Coyle, Hejazi, Melencia, et al. (2021)). # see what algorithms are available for a continuous outcome # (similar can be done for a binary outcome) sl3_list_learners(&quot;continuous&quot;) ## [1] &quot;Lrnr_arima&quot; &quot;Lrnr_bartMachine&quot; ## [3] &quot;Lrnr_bilstm&quot; &quot;Lrnr_bound&quot; ## [5] &quot;Lrnr_caret&quot; &quot;Lrnr_cv_selector&quot; ## [7] &quot;Lrnr_dbarts&quot; &quot;Lrnr_earth&quot; ## [9] &quot;Lrnr_expSmooth&quot; &quot;Lrnr_gam&quot; ## [11] &quot;Lrnr_gbm&quot; &quot;Lrnr_glm&quot; ## [13] &quot;Lrnr_glm_fast&quot; &quot;Lrnr_glmnet&quot; ## [15] &quot;Lrnr_grf&quot; &quot;Lrnr_gru_keras&quot; ## [17] &quot;Lrnr_gts&quot; &quot;Lrnr_h2o_glm&quot; ## [19] &quot;Lrnr_h2o_grid&quot; &quot;Lrnr_hal9001&quot; ## [21] &quot;Lrnr_HarmonicReg&quot; &quot;Lrnr_hts&quot; ## [23] &quot;Lrnr_lstm&quot; &quot;Lrnr_lstm_keras&quot; ## [25] &quot;Lrnr_mean&quot; &quot;Lrnr_multiple_ts&quot; ## [27] &quot;Lrnr_nnet&quot; &quot;Lrnr_nnls&quot; ## [29] &quot;Lrnr_optim&quot; &quot;Lrnr_pkg_SuperLearner&quot; ## [31] &quot;Lrnr_pkg_SuperLearner_method&quot; &quot;Lrnr_pkg_SuperLearner_screener&quot; ## [33] &quot;Lrnr_polspline&quot; &quot;Lrnr_randomForest&quot; ## [35] &quot;Lrnr_ranger&quot; &quot;Lrnr_rpart&quot; ## [37] &quot;Lrnr_rugarch&quot; &quot;Lrnr_screener_correlation&quot; ## [39] &quot;Lrnr_solnp&quot; &quot;Lrnr_stratified&quot; ## [41] &quot;Lrnr_svm&quot; &quot;Lrnr_tsDyn&quot; ## [43] &quot;Lrnr_xgboost&quot; The chosen candidate algorithms can be created and collected in a Stack. # initialize candidate learners lrn_glm &lt;- make_learner(Lrnr_glm) lrn_lasso &lt;- make_learner(Lrnr_glmnet) # alpha default is 1 xgb_5 &lt;- Lrnr_xgboost$new(nrounds = 5) # collect learners in stack stack &lt;- make_learner( Stack, lrn_glm, lrn_lasso, xgb_5 ) The stack is then given to the SuperLearner. # to make an ensemble SuperLearner sl_meta &lt;- Lrnr_nnls$new() sl &lt;- Lrnr_sl$new( learners = stack, metalearner = sl_meta) # or a discrete SuperLearner sl_disc_meta &lt;- Lrnr_cv_selector$new() sl_disc &lt;- Lrnr_sl$new( learners = stack, metalearner = sl_disc_meta ) The SuperLearner is then trained on the sl3 task we created at the start and then it can be used to make predictions. set.seed(1444) # train SL sl_fit &lt;- sl$train(rhc_task) # or for discrete SL # sl_fit &lt;- sl_disc$train(rhc_task) # make predictions sl3_data &lt;- ObsData sl3_data$sl_preds &lt;- sl_fit$predict() sl3_est &lt;- mean(sl3_data$sl_preds[sl3_data$A == 1]) - mean(sl3_data$sl_preds[sl3_data$A == 0]) sl3_est ## [1] 5.331201 saveRDS(sl3_est, file = &quot;data/sl3.RDS&quot;) Notes about the sl3 package: fairly easy to implement &amp; understand structure large selection of candidate algorithms provided unsure why result is so different very different structure from SuperLearner library, but very customizable could use more explanations of when to use what metalearner and what exactly the structure of the metalearner construction means Most helpful resources: tlverse sl3 page sl3 GitHub repository tlverse handbook chapter 6 Vignettes in R 7.4 RHC results Gathering previously saved results: fit.reg &lt;- readRDS(file = &quot;data/adjreg.RDS&quot;) TEr &lt;- fit.reg$coefficients[2] CIr &lt;- as.numeric(confint(fit.reg, &#39;A&#39;)) fit.matched &lt;- readRDS(file = &quot;data/match.RDS&quot;) TEm &lt;- fit.matched$coefficients[2] CIm &lt;- as.numeric(confint(fit.matched, &#39;A&#39;)) TEg &lt;- readRDS(file = &quot;data/gcomp.RDS&quot;) CIg &lt;- readRDS(file = &quot;data/gcompci.RDS&quot;) CIgc &lt;- CIg$percent[4:5] TE1g &lt;- readRDS(file = &quot;data/gcompxg.RDS&quot;) TE2g &lt;- readRDS(file = &quot;data/gcompls.RDS&quot;) TE3g &lt;- readRDS(file = &quot;data/gcompsl.RDS&quot;) ipw &lt;- readRDS(file = &quot;data/ipw.RDS&quot;) TEi &lt;- ipw$coefficients[2] CIi &lt;- as.numeric(confint(ipw, &#39;A&#39;)) ipwsl &lt;- readRDS(file = &quot;data/ipwsl.RDS&quot;) TEsli &lt;- ipwsl$coefficients[2] CIsli &lt;- as.numeric(confint(ipwsl, &#39;A&#39;)) tmleh &lt;- readRDS(file = &quot;data/tmlepointh.RDS&quot;) tmlecih &lt;- readRDS(file = &quot;data/tmlecih.RDS&quot;) tmlesl &lt;- readRDS(file = &quot;data/tmle.RDS&quot;) tmlecisl &lt;- readRDS(file = &quot;data/tmleci.RDS&quot;) slp &lt;- readRDS(file = &quot;data/sl3.RDS&quot;) ci.b &lt;- rep(NA,2) ks &lt;- 2.01 ci.ks &lt;- c(0.6,3.41) point &lt;- as.numeric(c(TEr, TEm, TEg, TE1g, TE2g, TE3g, TEi, TEsli, tmleh, tmlesl, slp, ks)) CIs &lt;- cbind(CIr, CIm, CIgc, ci.b, ci.b, ci.b, CIi, CIsli, tmlecih, tmlecisl, ci.b, ci.ks) method.list &lt;- c(&quot;Adj. Reg&quot;,&quot;PS match&quot;, &quot;G-comp (logistic)&quot;,&quot;G-comp (xgboost)&quot;, &quot;G-comp (lasso)&quot;, &quot;G-comp (SL)&quot;, &quot;IPW (logistic)&quot;, &quot;IPW (SL)&quot;, &quot;TMLE (9 steps)&quot;, &quot;TMLE (package)&quot;, &quot;sl3 (package)&quot;, &quot;Keele and Small (2021) paper&quot;) results &lt;- data.frame(method.list) results$Estimate &lt;- round(point,2) results$`2.5 %` &lt;- CIs[1,] results$`97.5 %` &lt;- CIs[2,] kable(results,digits = 2)%&gt;% row_spec(10, bold = TRUE, color = &quot;white&quot;, background = &quot;#D7261E&quot;) method.list Estimate 2.5 % 97.5 % Adj. Reg 2.90 1.37 4.43 PS match 3.25 1.45 5.05 G-comp (logistic) 2.90 1.52 4.59 G-comp (xgboost) 4.11 G-comp (lasso) 2.72 G-comp (SL) 1.91 IPW (logistic) 3.24 1.88 4.60 IPW (SL) 2.90 1.51 4.29 TMLE (9 steps) 2.73 1.59 3.87 TMLE (package) 2.87 1.77 3.97 sl3 (package) 5.33 Keele and Small (2021) paper 2.01 0.60 3.41 Keele and Small (2021) used superlearner based on an ensemble of 3 different learners: (1) GLM, (2) random forests, and (3) LASSO. 7.5 Other packages Other packages that may be useful: Package Resources Notes ltmle CRAN vignette Longitudinal tmle3 GitHub, framework overview, tlverse handbook tmle3 is still under development aipw GitHub, CRAN vignette Newer package for AIPW (another DR method) Others van der Laan research group You can find many other related packages on CRAN or GitHub. References "],["final-words.html", "Chapter 8 Final Words 8.1 Select variables judiciously 8.2 Why SL and TMLE 8.3 Further reading", " Chapter 8 Final Words 8.1 Select variables judiciously Figure 8.1: Variable roles: A = exposure or treatment; Y = outcome; L = confounder; R = risk factor for Y; M = mediator; C = collider; E = effect of Y; I = instrument; u = unmeasured confounder; P = proxy of U; N = noise variable Think about the role of variables first ideally include confounders to reduce bias consider including risk factor for outcome for greater accuracy IV, collider, mediators, effect of outcome, noise variables should be avoided if something is unmeasured, consider adding proxy (with caution) If you do not have subject area expertise, talk to experts do pre-screening sparse binary variables highly collinear variables Relying on just a blackbox ML method may be dangerous to identify the roles of variables in the relationship of interest. 8.2 Why SL and TMLE 8.2.1 Prediction goal Assuming all covariates are measured, parametric models such as linear and logistic regressions are very efficient, but relies on strong assumptions. In real-world scenarios, it is often hard (if not impossible) to guess the correct specification of the right hand side of the regression equation. Machine learning (ML) methods are very helpful for prediction goals. They are also helpful in identifying complex functions (non-linearities and non-additive terms) of the covariates (again, assuming they are measured). There are many ML methods, but the procedures are very different, and they come with their own advantages and disadvantages. In a given real data, it is hard to apriori predict which is the best ML algorithm for a given problem. Thats where super learner is helpful in combining strength from various algorithms, and producing 1 prediction column that has optimal statistical properties. 8.2.2 Causal inference For causal inference goals (when we have a primary exposure of interest), machine learning methods are often misleading. This is primarily due to the fact that they usually do not have an inherent mechanism of focusing on primary exposure (RHC in this example); and treats the primary exposure as any other predictors. When using g-computation with ML methods, estimation of variance becomes a difficult problem. Generalized procedures such as robust SE or bootstrap methods are not supported by theory. Thats where TMLE methods shine, with the help of its important statistical properties (double robustness, finite sample properties). 8.2.3 Identifiability assumptions However, causal inference requires satisfying identifiability assumptions for us to interpret causality based on association measures from statistical models (see below). Many of these assumptions are not empirically testable. That is why, it is extremely important to work with subject area experts to assess the plausibility of those assumptions in the given context. No ML method, no matter how fancy it is, can automatically produce estimates that can be directly interpreted as causal, unless the identifiability assumptions are properly taken into account. Conditional Exchangeability \\(Y(1), Y(0) \\perp A | L\\) Treatment assignment is independent of the potential outcome, given covariates Positivity \\(0 &lt; P(A=1 | L) &lt; 1\\) Subjects are eligible to receive both treatment, given covariates Consistency \\(Y = Y(a) \\forall A=a\\) No multiple version of the treatment; and well defined treatment 8.3 Further reading 8.3.1 Key articles TMLE Procedure: Luque-Fernandez et al. (2018) Schuler and Rose (2017) Super learner: Rose (2013) Naimi and Balzer (2018) 8.3.2 Additional readings Rose (2020) Snowden, Rose, and Mortimer (2011) Naimi, Cole, and Kennedy (2017) Austin and Stuart (2015) Naimi, Mishler, and Kennedy (2017) Balzer and Westling (2021) 8.3.3 Workshops Highly recommend joining SER if interested in Epi methods development. The following workshops and summer course are very useful. SER Workshop Introduction to Parametric and Semi-parametric Estimators for Causal Inference by Laura B. Balzer &amp; Jennifer Ahern, 2020 SER Workshop Machine Learning and Artificial Intelligence for Causal Inference and Prediction: A Primer by Naimi A, 2021 SISCER Modern Statistical Learning for Observational Data by Marco Carone, David Benkeser, 2021 8.3.4 Recorded webinars The following webinars and workshops are freely accessible, and great for understanding the intuitions, theories and mechanisms behind these methods! 8.3.4.1 Introductory materials An Introduction to Targeted Maximum Likelihood Estimation of Causal Effects by Susan Gruber (Putnam Data Sciences) Practical Considerations for Specifying a Super Learner by Rachael Phillips (Putnam Data Sciences) 8.3.4.2 More theory talks Targeted Machine Learning for Causal Inference based on Real World Data by Mark van der Laan (Putnam Data Sciences) An introduction to Super Learning by Eric Polly (Putnam Data Sciences) Cross-validated Targeted Maximum Likelihood Estimation (CV-TMLE) by Alan Hubbard (Putnam Data Sciences) Higher order Targeted Maximum Likelihood Estimation by Mark van der Laan (Online Causal Inference Seminar) Targeted learning for the estimation of drug safety and effectiveness: Getting better answers by asking better questions by Mireille Schnitzer (CNODES) 8.3.4.3 More applied talks Applications of Targeted Maximum Likelihood Estimation by Laura Balzar (UCSF Epi &amp; Biostats) Applying targeted maximum likelihood estimation to pharmacoepidemiology by Menglan Pang (CNODES) 8.3.4.4 Blog Kats Stats by Katherine Hoffman towardsdatascience by Yao Yang The Research Group of Mark van der Laan by Mark van der Laan References "],["references.html", "References", " References "]]
